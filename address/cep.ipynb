{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "      h1, h2, h3, h4 {\n",
    "        color: #bbb;\n",
    "      }\n",
    "      ol {\n",
    "        counter-reset: item;\n",
    "        font-size: 1.2rem;\n",
    "        font-weight: 200;\n",
    "      }\n",
    "      li {\n",
    "        display: block;\n",
    "        color: #aaa;\n",
    "      }\n",
    "      li:before {\n",
    "        content: counters(item, \".\") \" \";\n",
    "        counter-increment: item;\n",
    "      }\n",
    "    </style>\n",
    "\n",
    "<h1>Equalização dos CEP com Endereços</h1>\n",
    "<ol>\n",
    "    <li>importar as depedências</li>\n",
    "    <li>configurar as variáveis de ambiente</li>\n",
    "    <li>fazer download da base de dados\n",
    "      <ol>\n",
    "          <li>fazer a leitura da base com pandas</li>\n",
    "      </ol>\n",
    "    </li>\n",
    "    <li>fazer a exploração da base\n",
    "      <ol>\n",
    "          <li>implementar lógica de exclusão de dados nulos</li>\n",
    "          <li>fazer atualização da base de cep</li>\n",
    "      </ol>\n",
    "    </li>\n",
    "    <li>criar a rotina de tratamento dos dados</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">1. Importar as depedências de desenvolvimento</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from unicodedata import normalize\n",
    "from urllib import request\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.version_service import VersionService\n",
    "from keys.generate_key import GenerateKey as key\n",
    "ver_service = VersionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE = os.path.join('..', 'storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_TB_ESTABELECIMENTO = ver_service.get_last_version(key.FILENAME_TB_ESTABELECIMENTO, key.EXT_CSV, STORAGE)\n",
    "FILENAME_CEP = ver_service.get_last_version(key.FILENAME_CEP, key.EXT_CSV, STORAGE)\n",
    "FILENAME_JSON = ver_service.get_last_version(key.FILENAME_CEP,key.EXT_JSON, STORAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">2. Configurar as variáveis de ambiente</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = {}\n",
    "\n",
    "with open(os.path.join('../', '.env'), encoding='utf-8') as env:\n",
    "    files = env.readlines()\n",
    "    \n",
    "    for file in files:\n",
    "        environment[str(file.split('=')[0])] = str(file.split('=')[1]).strip()\n",
    "    env.close()\n",
    "\n",
    "environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build url\n",
    "def get_url(path: str) -> str:\n",
    "    return '{}:{}{}'.format(environment.get('URL'), environment.get('PORT'), path)\n",
    "\n",
    "# normalize unicode\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    return normalize('NFKD', text).encode('ASCII','ignore').decode('ASCII')\n",
    "\n",
    "# jon column and remove duplicated\n",
    "def join_columns(text: str) -> str:\n",
    "    return ' '.join(dict.fromkeys(normalize_unicode(text).lower().split()))\n",
    "\n",
    "# combine column\n",
    "def combine_columns(df: pd.DataFrame, col_source: str, col_target: str, delimiter:str = ' '):\n",
    "    join = lambda s1, s2: join_columns(str(s1 + delimiter + s2))\n",
    "    df[col_source] = df[col_source].combine(df[col_target], join)\n",
    "\n",
    "# fillna columns\n",
    "def filla_columns(df: pd.DataFrame, cols: list, value = ''):\n",
    "    for col in cols:\n",
    "        df[col].fillna(value=value, inplace=True)\n",
    "\n",
    "# to lower case\n",
    "def to_lower(df: pd.DataFrame, col: str):\n",
    "    df[col] = df[col].str.lower()\n",
    "\n",
    "# calculate distance euclidian\n",
    "def distance_euclidian(coord_origin: tuple, coord_dest:tuple) -> float:\n",
    "    return math.sqrt(((coord_origin[1] - coord_origin[0]) **2) + ((coord_dest[1] - coord_dest[0]) **2))\n",
    "\n",
    "# calculate distance euclidian\n",
    "def distance_euclidian2(coord_origin: tuple, coord_dest:tuple) -> float:\n",
    "    return math.sqrt(math.pow((coord_origin[1] - coord_origin[0]), 2) + math.pow(coord_dest[1] - coord_dest[0], 2))\n",
    "\n",
    "# calculate distance manhattan\n",
    "def distance_manhatran(coord_origin: list, coord_dest:list) -> float:\n",
    "    return  np.abs(coord_origin[1] - coord_origin[0]) + np.abs(coord_dest[1] - coord_dest[0])\n",
    "\n",
    "def k_nearst(coord_origins, coord_dests, point):\n",
    "\n",
    "    for i in range(len(coord_origins)):\n",
    "        print(coord_origins[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">3. Fazer download da base de dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: run if not exist file\n",
    "response = request.urlopen(get_url('/export-csv-cep'))\n",
    "raw_data = response.read()\n",
    "encoding = response.info().get_content_charset('utf8')\n",
    "filename = ver_service.get_next_version(key.FILENAME_CEP, key.EXT_CSV, STORAGE)\n",
    "\n",
    "with open(os.path.join(STORAGE, filename), 'w', encoding='utf-8') as csv:\n",
    "    csv.writelines(raw_data.decode(encoding))\n",
    "    csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color: #ccc\">3.1 fazer a leitura da base com pandas</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esta = pd.read_csv(os.path.join(STORAGE, FILENAME_TB_ESTABELECIMENTO), sep=';', encoding='utf-8', low_memory=False, dtype=str)\n",
    "df_cep = pd.read_csv(os.path.join(STORAGE, FILENAME_CEP), sep=',', encoding='utf-8', low_memory=False, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">4. fazer a exploração da base</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total de registro e colunas\n",
    "print('estabelecimento: {}'.format(df_esta.shape))\n",
    "print(80*'#')\n",
    "print('cep: {}'.format(df_cep.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cep.info())\n",
    "print(80*'#')\n",
    "print(df_esta.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address = df_esta[['ID','CEP', 'BAIRRO', 'COMPLEMENTO', 'ESTADO', 'LOGRADOURO', 'NUMERO', 'TIPO_LOGRADOURO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">4.1 implementar lógica de exclusão de dados nulos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cep.isnull().sum())\n",
    "print(80*\"#\")\n",
    "display(df_address.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurence\n",
    "display(df_address.value_counts())\n",
    "print(80*'#')\n",
    "display(df_cep.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_address['CEP'].isin(df_cep['cep']).value_counts())\n",
    "print(80*'#')\n",
    "display(df_cep['cep'].isin(df_address['CEP']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cep_left = df_esta[~df_esta['CEP'].isin(df_cep['cep'])]\n",
    "cep_left = cep_left[['CEP', 'BAIRRO', 'COMPLEMENTO', 'ESTADO', 'LOGRADOURO', 'NUMERO']]\n",
    "columns={'CEP':'cep','BAIRRO':'bairro','COMPLEMENTO':'complemento','LOGRADOURO':'lougradouro','NUMERO':'numero','ESTADO':'estado'}\n",
    "cep_left.rename(columns=columns, inplace=True)\n",
    "cep_left['cidade_estado'] = cep_left['bairro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filla_columns(cep_left, ['estado', 'bairro', 'complemento', 'cidade_estado'])\n",
    "filla_columns(cep_left, ['cep'], '00000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_columns(cep_left, 'cidade_estado', 'estado', '/')\n",
    "combine_columns(cep_left, 'lougradouro', 'numero', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cep_left = cep_left[cep_left.columns.difference(['estado', 'numero'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cep_updated = pd.concat([df_cep, cep_left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cep_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('check merge: {}'.format(df_cep_updated.shape[0] - df_cep.shape[0] == cep_left.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #ccc\">4.2 Fazer atualização da base de cep</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_cep_version = ver_service.get_next_version(key.FILENAME_CEP, key.EXT_CSV, os.path.join(STORAGE))\n",
    "latest_cep_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(df_cep_updated.iloc[0].to_dict(), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cep_updated.to_csv(os.path.join(STORAGE, latest_cep_version), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_CEP = ver_service.get_last_version(key.FILENAME_CEP, key.EXT_CSV, STORAGE)\n",
    "df_cep = pd.read_csv(os.path.join(STORAGE, FILENAME_CEP), sep=',', encoding='utf-8', low_memory=False, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_euclidian((0.2, 0.1), (0.3, -0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_euclidian2((0.2, 0.1), (0.3, -0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_manhatran((0.2, 0.1), (0.3, -0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 1000\n",
    " # Gera os pontos de base, aleatoriamente\n",
    "lat_origin, long_origin = np.random.rand(2, 1)\n",
    "\n",
    "# Gera o ponto k, também aleatoriamente\n",
    "lat_dest, long_dest = np.random.rand(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29434753, 0.86545192, 0.40304582, 0.92200864, 0.42387968,\n",
       "       0.58343485, 0.50499207, 0.3630296 , 0.15657585, 0.24866706])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.922008637271035,\n",
       "  0.2943475278109503,\n",
       "  0.1565758459534905,\n",
       "  0.2486670601368588,\n",
       "  0.4238796824745579,\n",
       "  0.5049920702348204,\n",
       "  0.5834348477648943,\n",
       "  0.363029597763903,\n",
       "  0.4030458161764987,\n",
       "  0.8654519169742924],\n",
       " [0.917387516098454,\n",
       "  0.21677063326327017,\n",
       "  0.026811348143088942,\n",
       "  0.11159770166475524,\n",
       "  0.15901443706579366,\n",
       "  0.22591422144514262,\n",
       "  0.20576162237286288,\n",
       "  0.8222203635132157,\n",
       "  0.876568848197626,\n",
       "  0.06840906189440088])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = {}\n",
    "for i in range(len(lat_dest)):\n",
    "    dist = np.sqrt(np.power(long_origin[0] - lat_origin[0], 2) + np.power(long_dest[i] - lat_dest[i], 2))\n",
    "    distances[dist] = [long_dest[i], lat_dest[i]]\n",
    "\n",
    "distances_sorted = sorted(distances)\n",
    "\n",
    "pX = []\n",
    "pY = []\n",
    "n = np.min([10, len(lat_dest)])\n",
    "\n",
    "for i in range(n):\n",
    "    pX.append(distances[distances_sorted[i]][0])\n",
    "    pY.append(distances[distances_sorted[i]][1])\n",
    "\n",
    "pX, pY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.009814393018307443,\n",
       "  0.031230690090121138,\n",
       "  0.0863289236282837,\n",
       "  0.2266767130402677,\n",
       "  0.006802558010464588,\n",
       "  0.25451019494356186,\n",
       "  0.16747246531219973,\n",
       "  0.03806380525801756,\n",
       "  0.25731887333953873,\n",
       "  0.07750635718386989],\n",
       " [0.01826728634599739,\n",
       "  0.17394330445316697,\n",
       "  0.1742162285479777,\n",
       "  0.10109142953346328,\n",
       "  0.27631628401214614,\n",
       "  0.09545924569210595,\n",
       "  0.2639432262953745,\n",
       "  0.31688102792749584,\n",
       "  0.22557616446280782,\n",
       "  0.34464384916968593])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número total de pontos (base)\n",
    "tam = 100\n",
    "# Número desejado de pontos mais próximos\n",
    "n = 10\n",
    "\n",
    " # Gera os pontos de base, aleatoriamente\n",
    "bx, by = np.random.rand(2, tam)\n",
    "\n",
    "# Gera o ponto k, também aleatoriamente\n",
    "kx, ky = np.random.rand(2, 1)\n",
    "\n",
    "distancias = {}\n",
    "for i in range(len(bx)):\n",
    "    distancia, = np.sqrt(np.power(bx[i] - kx, 2) + np.power(by[i] - ky, 2))\n",
    "    distancias[distancia] = [bx[i], by[i]]\n",
    "\n",
    "# Organiza as distâncias em ordem crescente\n",
    "ordenadas = sorted(distancias)\n",
    "\n",
    "# Então, devolve os pontos nas n primeiras entradas\n",
    "# da lista ordenada (pegando as coordenadas do dicionário)\n",
    "pX = []\n",
    "pY = []\n",
    "n = np.min([n, len(bx)])\n",
    "for i in range(n):\n",
    "    coords = distancias[ordenadas[i]]\n",
    "    pX.append(coords[0])\n",
    "    pY.append(coords[1])\n",
    "\n",
    "pX, pY\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37d749834043cc8bcf9500ddac590bcfc07020a4e948b1c7aab57c3f0cf1e0ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
