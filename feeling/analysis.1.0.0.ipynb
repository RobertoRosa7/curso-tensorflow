{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import pickle as pick\n",
    "import numpy as np\n",
    "\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from string import punctuation\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('rslp')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "nltk_lists = ['tokenizers/punkt', 'stemmers/rslp', 'corpora/stopwords']\n",
    "\n",
    "for name in nltk_lists:\n",
    "    try:\n",
    "        nltk.data.find(name)\n",
    "    except LookupError:\n",
    "        nltk.download(name.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('storage', 'base_sentiment.1.0.0.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64f7bba758ec2b013e226a67</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>2023-09-05T20:37:08.869Z</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64f7bba758ec2b013e226a68</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>2023-09-05T20:37:08.869Z</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64f7bba758ec2b013e226a69</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>2023-09-05T20:37:08.869Z</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64f7bba758ec2b013e226a6a</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>2023-09-05T20:37:08.869Z</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64f7bba758ec2b013e226a6b</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>2023-09-05T20:37:08.869Z</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  64f7bba758ec2b013e226a67   \n",
       "1  64f7bba758ec2b013e226a68   \n",
       "2  64f7bba758ec2b013e226a69   \n",
       "3  64f7bba758ec2b013e226a6a   \n",
       "4  64f7bba758ec2b013e226a6b   \n",
       "\n",
       "                                                text  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...   \n",
       "\n",
       "                 created_at sentiment  \n",
       "0  2023-09-05T20:37:08.869Z  negative  \n",
       "1  2023-09-05T20:37:08.869Z  negative  \n",
       "2  2023-09-05T20:37:08.869Z  negative  \n",
       "3  2023-09-05T20:37:08.869Z  negative  \n",
       "4  2023-09-05T20:37:08.869Z  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classificacao'] = df.sentiment.replace([\"negative\", 'positive'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "bag_of_words = vetorizar.fit_transform(df['text'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bag_of_words, df['classificacao'], random_state=42)\n",
    "\n",
    "regressao_logistica = LogisticRegression(solver='liblinear')\n",
    "regressao_logistica.fit(x_train, y_train)\n",
    "accuracia = regressao_logistica.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=2500,\n",
    "    strip_accents=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    stop_words=nltk.corpus.stopwords.words('portuguese'), \n",
    "    min_df=7, \n",
    "    max_df=0.8\n",
    ")\n",
    "regressao_logistica = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "regressao_logistica.fit(X_train,y_train)\n",
    "\n",
    "preds = regressao_logistica.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747270521633643"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
