{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone project 2 - SkimLit\n",
    "\n",
    "## SkimLit sequece problem: Many to one\n",
    "\n",
    "To investigate the efficacy of @week of daily low-dose oral prednisolone in improving pain, mobility, systemic low-grade inflamation in the short term and wether the effect would be sustained at @week in order adults with moderate to sever knee osteoarthritis (OA).\n",
    "\n",
    "## What we're going to cover\n",
    "\n",
    "* Download a text dataset (PubMed 200k RCT)\n",
    "* Writing a preprocessing function for our text data\n",
    "* Setting up multiple modelling experiments with differents levels of embeddings\n",
    "* Building a multimodal model to take in different source of data\n",
    "    - Replicating the model powering https://arxiv.org/abs/1710.06071\n",
    "* Finding the most wrong prediction example\n",
    "\n",
    "see: https://www.nltk.org/install.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1650 Ti (UUID: GPU-396e0d2a-a22a-a57f-bd25-8f6297e10119)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset\n",
    "\n",
    "Since we'll be replicating a paper above (PubMed 200k RCT), let's download the data they used.\n",
    "\n",
    "We can do so from the authors GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.5\n",
      "tensorflow: 2.9.3\n",
      "sklearn: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import multiprocessing\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# add path root project to read helper fuctions\n",
    "sys.path.append(os.path.join('../'))\n",
    "\n",
    "from helper_functions import calculate_results\n",
    "\n",
    "print(f'pandas: {pd.__version__}')\n",
    "print(f'tensorflow: {tf.__version__}')\n",
    "print(f'sklearn: {skl.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_lists = ['tokenizers/punkt', 'stemmers/rslp', 'corpora/stopwords']\n",
    "\n",
    "for name in nltk_lists:\n",
    "    try:\n",
    "        nltk.data.find(name)\n",
    "    except LookupError:\n",
    "        nltk.download(name.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE = os.path.join('../../', 'storage')\n",
    "MODEL_PATH = f'{STORAGE}/models'\n",
    "NLP = f'{STORAGE}/nlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
    "# shutil.move('pubmed-rct', f'{NLP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev.txt', 'test.txt', 'train.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list dir and see your content\n",
    "os.listdir(f'{NLP}/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start our experiments using 20k dataset with number replaced by '@' sign\n",
    "data_dir = f'{NLP}/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../storage/nlp/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " '../../storage/nlp/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " '../../storage/nlp/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all of the filenames in the target directory\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Now we've got some text data, it's time to become one with it.\n",
    "\n",
    "And one of the best ways to become one with the data is to...\n",
    "\n",
    "> Visualize, Visualize, Visualize\n",
    "\n",
    "So with that in mind, let's write a function to read in all of the lines of a target text file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\" \n",
    "    Reads filename (a txt filename) and returns the lines of a text as a list\n",
    "    Args:\n",
    "        filename:  a string  containing the target filepath\n",
    "    Returns:\n",
    "        A list of strings with one string per line from the target filename\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines\n",
    "\n",
    "train_lines = get_lines(data_dir + 'train.txt') # read the lines with the training file\n",
    "train_lines[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about how we want our data to look\n",
    "\n",
    "How I think our data would be best represented\n",
    "\n",
    "```json\n",
    "[   \n",
    "    {\n",
    "        \"line_number\":0,\n",
    "        \"target\": \"BACKGROUND\",\n",
    "        \"text\":\" 'Serum levels of interleukin @ ( IL-@ ) , IL-@  and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n'\",\n",
    "        \"total_lines\": 11\n",
    "    }\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "Let's write a function which turns each of our dataset into the above format so we can continue to prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        filename: (str) required\n",
    "    Returns:\n",
    "        A list of dictionaries of abstract line data.\n",
    "\n",
    "        Takes in filename, reads it contents and sorts through each line, extracting\n",
    "        things like the target label, the text of the sentence, how many sentences are\n",
    "        in the current abstract and what sentence number the target line is.\n",
    "    \"\"\"\n",
    "    input_lines = get_lines(filename) # get all lines from filename\n",
    "    abstract_lines = \"\" # create an empty abstract\n",
    "    abstract_sample = [] # create an empty list\n",
    "\n",
    "    # loop through each line in the target file\n",
    "    for line in input_lines:\n",
    "        if line.startswith('###'): # check if line start with ###\n",
    "            # get id from line\n",
    "            abstract_id = line\n",
    "\n",
    "            # reset the abstract string if the line is an ID line\n",
    "            abstract_lines = \"\" \n",
    "        elif line.isspace(): # check line is a new line\n",
    "            # split abstract into separate lines\n",
    "            abstract_line_split = abstract_lines.splitlines()\n",
    "\n",
    "            # iterate through each line in a single abstract and count them at the same time\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                # create an empty dictionary for each line\n",
    "                line_data = {}\n",
    "                \n",
    "                # split target label from text\n",
    "                target_text_split = abstract_line.split('\\t')\n",
    "                \n",
    "                # get target label\n",
    "                line_data['target'] = target_text_split[0]\n",
    "                \n",
    "                # get target text and lower it\n",
    "                line_data['text'] = target_text_split[1].lower()\n",
    "                \n",
    "                # what number does the line appear in\n",
    "                line_data['number'] = abstract_line_number\n",
    "                \n",
    "                # how many total lines are there in the target abstract? (start from 0)\n",
    "                line_data['total_line'] = len(abstract_line_split) - 1\n",
    "                \n",
    "                # add line data to abstract sample list\n",
    "                abstract_sample.append(line_data)\n",
    "        else: # if the above conditions aren't fulfilled the line contains a labelled sentences \n",
    "            abstract_lines += line\n",
    "            \n",
    "    return abstract_sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# get data from file and preprocess it\n",
    "\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + 'train.txt')\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + 'dev.txt') # dev is another name for validation data\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + 'test.txt')\n",
    "\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'number': 0,\n",
       "  'total_line': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'number': 1,\n",
       "  'total_line': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'number': 2,\n",
       "  'total_line': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'number': 3,\n",
       "  'total_line': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'number': 4,\n",
       "  'total_line': 11}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first abstract of our training data\n",
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to visualize our train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>number</th>\n",
       "      <th>total_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...       0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...       1   \n",
       "2    METHODS  outcome measures included pain reduction and i...       2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...       3   \n",
       "4    METHODS  secondary outcome measures included the wester...       4   \n",
       "\n",
       "   total_line  \n",
       "0          11  \n",
       "1          11  \n",
       "2          11  \n",
       "3          11  \n",
       "4          11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how are distribution of labels in training data\n",
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's check the length of different lines\n",
    "train_df['total_line'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert abstract text line to list\n",
    "train_sentences = train_df['text'].tolist()\n",
    "val_sentences = val_df['text'].tolist()\n",
    "test_sentences = test_df['text'].tolist()\n",
    "\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make numeric label (ML models require numeric label)\n",
    "\n",
    "see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "see: https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "\n",
    "**WARNING**: Tensorflow is uncompatible with matrix sparse so use hyperameter false in OneHotEncoder of sklearn preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoder\n",
    "one_hot_encoder = skl.preprocessing.OneHotEncoder(sparse=False) # we want non-sparse matrix\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# check what trainining one hot encoder look like\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels ('target' column) and encode them into integers\n",
    "label_encoder = skl.preprocessing.LabelEncoder()\n",
    "train_labels_label_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
    "val_labels_label_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
    "test_labels_label_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
    "\n",
    "# check what training label look like\n",
    "train_labels_label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class name and number of classes from LabelEncoder intances\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names =  label_encoder.classes_\n",
    "\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model 0 baseline\n",
    "model_0 = Pipeline([ \n",
    "    ('tf-idf', TfidfVectorizer()),  # convert words to number using tf-idf\n",
    "    ('clf', MultinomialNB()) # model text\n",
    "])\n",
    "\n",
    "model_0_history = model_0.fit(train_sentences, train_labels_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.score(val_sentences, val_labels_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some predictions using our baseline\n",
    "model_0_preds = model_0.predict(val_sentences)\n",
    "model_0_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0_results</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy        f1  precision    recall\n",
       "model_0_results  0.721832  0.698925   0.718647  0.721832"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results = calculate_results(y_true=val_labels_label_encoded, y_pred=model_0_preds)\n",
    "model_results = pd.DataFrame({'model_0_results': model_0_results})\n",
    "model_results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data (the text) for deep sequence models\n",
    "\n",
    "Before we start building deeper models, we've got to create vectorization and embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180040"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words there are in our train_sentences: https://arxiv.org/pdf/1710.06071.pdf\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "len(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long is each sentence on average?\n",
    "np.mean(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how long is each sentence on average?\n",
    "sum(sent_lens)/len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribuition look like?\n",
    "ax = plt.hist(sent_lens, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of examples?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length in the training set\n",
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 68000\n",
    "\n",
    "# create text vectorizer\n",
    "text_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_tokens, # number of words in vocab\n",
    "                                                                               output_sequence_length=output_seq_len,\n",
    "                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt text vecotorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "( funded by novartis pharmaceuticals ; clinicaltrials.gov number , nct@ . )\n",
      "\n",
      "Length of text: 12\n",
      "\n",
      "Vectorizer text: [[1644   22 8865 5716  275  154  176    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Length Vectorizer: 55\n"
     ]
    }
   ],
   "source": [
    "target_sentence = random.choice(train_sentences)\n",
    "print(f'Text:\\n{target_sentence}')\n",
    "print(f'\\nLength of text: {len(target_sentence.split())}')\n",
    "print(f'\\nVectorizer text: {text_vectorizer([target_sentence])}')\n",
    "print(f'\\nLength Vectorizer: {len(text_vectorizer([target_sentence])[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 64841\n",
      "The most common words: ['', '[UNK]', 'the', 'and', 'of']\n",
      "The least common words: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# how many words in our training vocabulary\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "\n",
    "print(f'Number of words in vocab: {len(rct_20k_text_vocab)}')\n",
    "print(f'The most common words: {rct_20k_text_vocab[:5]}')\n",
    "print(f'The least common words: {rct_20k_text_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the config of text_vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token embedding layer\n",
    "token_embed = tf.keras.layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
    "                                        output_dim=128, # NOTE: different embedding sizes result in \n",
    "                                        mask_zero=False, # use masking to handle variable sequence length\n",
    "                                        name='token_embedding'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      " ( funded by novartis pharmaceuticals ; clinicaltrials.gov number , nct@ . )\n",
      "\n",
      "Sentence after vectorization (before embedding):\n",
      "[[1644   22 8865 5716  275  154  176    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Sentence after embedding:\n",
      "[[[ 0.0217021   0.04104478  0.01906792 ...  0.01469177  0.04880949\n",
      "    0.02034459]\n",
      "  [ 0.02473395 -0.03090371 -0.03165914 ... -0.03627148 -0.04011222\n",
      "    0.04439706]\n",
      "  [ 0.02827103  0.04741248  0.01287898 ...  0.03880515 -0.04351764\n",
      "    0.01031047]\n",
      "  ...\n",
      "  [-0.0217084   0.0287647   0.04522998 ...  0.02317541  0.02846965\n",
      "    0.00111149]\n",
      "  [-0.0217084   0.0287647   0.04522998 ...  0.02317541  0.02846965\n",
      "    0.00111149]\n",
      "  [-0.0217084   0.0287647   0.04522998 ...  0.02317541  0.02846965\n",
      "    0.00111149]]]\n",
      "\n",
      "Sentence after embedding shape:\n",
      "(1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "print(f'Sentence before vectorization:\\n {target_sentence}\\n')\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f'Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n')\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f'Sentence after embedding:\\n{embedded_sentence}\\n')\n",
    "print(f'Sentence after embedding shape:\\n{embedded_sentence.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into Tensorflow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDataset's and turn them into prefected dataset\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE),\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Conv1D with token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_conv1d_token_embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create Conv 1D model to process sequences\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # vectorize text input\n",
    "x = token_embed(x) # create embedding\n",
    "x = tf.keras.layers.Conv1D(filters=64, \n",
    "                           kernel_size=5, \n",
    "                           padding='same', \n",
    "                           activation='relu')(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector from conv layer\n",
    "outputs = tf.keras.layers.Dense(num_classes, \n",
    "                                activation='softmax')(x) # we have more than two class\n",
    "model_1 = tf.keras.Model(inputs, \n",
    "                         outputs,\n",
    "                         name='model_1_conv1d_token_embedding')\n",
    "\n",
    "# compile mode 1\n",
    "model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "# show summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 14s 11ms/step - loss: 0.9174 - accuracy: 0.6377 - val_loss: 0.6869 - val_accuracy: 0.7400\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6605 - accuracy: 0.7552 - val_loss: 0.6363 - val_accuracy: 0.7709\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6193 - accuracy: 0.7755 - val_loss: 0.5982 - val_accuracy: 0.7862\n"
     ]
    }
   ],
   "source": [
    "# fit the model with 10% of train_dataset\n",
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_dataset)), # use only 10%\n",
    "                              epochs=3,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_dataset)) # only validate on 10% of batches\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.6001 - accuracy: 0.7880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6000630259513855, 0.7879981398582458]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.5894939e-01, 1.8266617e-01, 7.4081935e-02, 2.3945451e-01,\n",
       "        4.4848010e-02],\n",
       "       [3.8709444e-01, 3.3382028e-01, 1.1391240e-02, 2.5909448e-01,\n",
       "        8.5994983e-03],\n",
       "       [1.4983892e-01, 1.4141123e-02, 2.9956575e-03, 8.3298272e-01,\n",
       "        4.1599531e-05],\n",
       "       ...,\n",
       "       [8.6756600e-06, 5.9895724e-04, 9.3955564e-04, 2.1459230e-06,\n",
       "        9.9845064e-01],\n",
       "       [5.8621913e-02, 4.3331090e-01, 9.2247739e-02, 7.4027702e-02,\n",
       "        3.4179169e-01],\n",
       "       [1.6997941e-01, 6.4720273e-01, 4.3870658e-02, 8.1843995e-02,\n",
       "        5.7103269e-02]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some predictions (out model predictions probabilities for each class)\n",
    "model_1_pred_prob = model_1.predict(val_dataset)\n",
    "model_1_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pred prob to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_prob, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0_results</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1_results</th>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.784934</td>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.785785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall        f1\n",
       "model_0_results  0.721832   0.718647  0.721832  0.698925\n",
       "model_1_results  0.787998   0.784934  0.787998  0.785785"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = calculate_results(y_true=val_labels_label_encoded, y_pred=model_1_preds)\n",
    "\n",
    "model_results = pd.DataFrame({'model_0_results': model_0_results,\n",
    "                              'model_1_results': model_1_results})\n",
    "model_results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Feature Extraction with Pretrained Model\n",
    "\n",
    "see: https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "see: http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc\n",
    "\n",
    "see: https://www.kaggle.com/code/chewzy/tutorial-how-to-train-your-custom-word-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_use = tf.keras.models.load_model(f'{MODEL_PATH}/tfhub_universal_sentence_encoder')\n",
    "\n",
    "tfhub_url = 'https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2'\n",
    "\n",
    "# create a Keras Layer using the pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(tfhub_url, \n",
    "                                        input_shape=[], \n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False, \n",
    "                                        name='USE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentences:\n",
      "recruitment and retention rates were higher in the hypertension trial than in the depression trial .\n"
     ]
    }
   ],
   "source": [
    "# Test out the pretrained embedding on a random sentences\n",
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f'Random sentences:\\n{random_train_sentence}')\n",
    "use_embedding_sentence = sentence_encoder_layer([random_train_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[ 1.02705453e-02, -5.82322218e-02,  5.57982698e-02,\n",
       "         3.22578126e-03, -3.12929899e-02,  3.99904624e-02,\n",
       "         5.42562529e-02, -6.26963302e-02,  2.11001816e-03,\n",
       "        -7.82094896e-02,  8.35885778e-02,  5.56731559e-02,\n",
       "         4.52157259e-02, -5.08031547e-02,  6.44710585e-02,\n",
       "         1.30524766e-03, -8.07760134e-02,  4.84571159e-02,\n",
       "         5.87291755e-02,  3.31200287e-02, -5.66596724e-02,\n",
       "         1.77634582e-02, -3.78421694e-02, -6.67186528e-02,\n",
       "         1.03339069e-02, -3.89228687e-02, -7.04813655e-03,\n",
       "         3.45692709e-02, -4.92400751e-02, -3.42898164e-03,\n",
       "         3.18175815e-02,  7.29513690e-02,  4.18896787e-02,\n",
       "         5.76057620e-02,  2.20471271e-03, -3.48908678e-02,\n",
       "        -5.06031029e-02, -7.36888498e-02, -4.85335710e-03,\n",
       "         4.65799682e-03, -5.57009391e-02,  3.67299318e-02,\n",
       "         4.17839102e-02, -1.93374194e-02,  1.83698703e-02,\n",
       "        -4.98627797e-02,  1.11699309e-02,  8.39989707e-02,\n",
       "        -5.02025755e-03, -2.73503177e-02, -2.79282909e-02,\n",
       "         9.95421875e-03, -5.52940890e-02,  5.93095794e-02,\n",
       "         5.51181510e-02,  8.17049388e-03, -1.76327564e-02,\n",
       "        -3.05910315e-02,  1.48745421e-02,  4.06988002e-02,\n",
       "         6.37920760e-03,  3.48633179e-03,  3.21947969e-02,\n",
       "         5.17043695e-02, -5.14302123e-03, -8.99542309e-03,\n",
       "         5.93232736e-02, -1.98646989e-02,  3.84388976e-02,\n",
       "        -3.21557000e-02,  7.07915872e-02, -1.54595040e-02,\n",
       "         6.93687843e-03, -1.45471729e-02,  4.02796045e-02,\n",
       "        -3.58413197e-02, -2.24277340e-02,  4.54149060e-02,\n",
       "         9.59284883e-03, -2.08233502e-02,  3.74669097e-02,\n",
       "         6.74230829e-02,  3.03503014e-02,  6.02278672e-02,\n",
       "        -5.60817719e-02,  5.24411201e-02,  3.65163735e-03,\n",
       "        -2.54754629e-02, -4.41882238e-02, -7.50204101e-02,\n",
       "        -5.97278029e-02,  3.38232936e-03,  1.68432631e-02,\n",
       "        -2.42604651e-02,  6.75409883e-02, -3.90222333e-02,\n",
       "        -3.37406807e-02, -1.35826934e-02, -2.35194191e-02,\n",
       "        -3.28789055e-02, -6.86436221e-02,  7.03096995e-03,\n",
       "        -6.11263663e-02, -9.98848770e-03,  6.34870818e-03,\n",
       "        -5.62835112e-02,  3.37883048e-02,  2.99496129e-02,\n",
       "        -6.89222217e-02, -6.41414896e-02,  1.13609266e-02,\n",
       "         1.88564137e-02, -1.74161009e-02,  2.82674339e-02,\n",
       "        -3.31228692e-03, -4.82205972e-02,  4.34705056e-02,\n",
       "        -6.60395622e-02, -3.97328241e-03,  8.40199590e-02,\n",
       "         4.23123427e-02,  6.65006563e-02,  6.18586950e-02,\n",
       "         6.58200011e-02, -2.09189933e-02,  1.44673549e-02,\n",
       "        -4.27763015e-02,  3.94189209e-02,  1.71733666e-02,\n",
       "         1.51348235e-02,  3.38814184e-02,  7.34621733e-02,\n",
       "        -1.53884646e-02, -5.77251427e-03, -1.99169070e-02,\n",
       "        -4.50850055e-02,  6.37887120e-02,  5.86250313e-02,\n",
       "         4.70074154e-02, -3.96486707e-02,  7.97239840e-02,\n",
       "        -6.30375445e-02, -3.66372839e-02,  3.08450870e-02,\n",
       "        -7.66788274e-02,  5.62262870e-02, -5.12924828e-02,\n",
       "         6.00924939e-02, -2.71588704e-03, -3.60885821e-02,\n",
       "         3.32094319e-02,  4.06455919e-02,  1.74572933e-02,\n",
       "        -1.05993822e-02,  7.68989995e-02,  1.82834659e-02,\n",
       "        -1.14953646e-03, -6.25563338e-02,  1.84748322e-02,\n",
       "        -9.36674885e-03,  3.04661924e-04, -6.32301718e-02,\n",
       "        -4.92267534e-02,  1.40522688e-03,  1.07487175e-03,\n",
       "        -1.50629431e-02, -5.35248071e-02,  2.77155507e-02,\n",
       "        -1.23535097e-02,  2.17875242e-02,  2.51723230e-02,\n",
       "        -8.33100155e-02,  4.66921479e-02,  5.63945062e-02,\n",
       "        -4.28898446e-02,  5.97490594e-02, -4.45362516e-02,\n",
       "         6.16470575e-02, -6.52488098e-02,  5.69761768e-02,\n",
       "        -2.66382862e-02,  2.42095590e-02,  4.58321385e-02,\n",
       "        -5.26415221e-02,  5.17585129e-02, -3.13249566e-02,\n",
       "         2.24888735e-02, -7.53512606e-02,  4.24422547e-02,\n",
       "        -1.00210197e-02,  5.92771778e-03, -5.43012135e-02,\n",
       "         2.40488704e-02,  7.57773072e-02,  6.63734898e-02,\n",
       "         1.24495039e-02,  4.14014198e-02,  4.45911735e-02,\n",
       "        -5.09195141e-02, -1.60545241e-02,  7.59172291e-02,\n",
       "        -6.86953515e-02, -2.74757762e-02,  2.50948276e-02,\n",
       "        -1.11726094e-02, -3.94866765e-02,  6.40575439e-02,\n",
       "        -1.03222486e-02, -3.37027945e-02, -3.96123454e-02,\n",
       "         3.67357656e-02, -2.91997679e-02, -5.14758863e-02,\n",
       "        -6.57305345e-02,  2.57961378e-02, -4.87973616e-02,\n",
       "         6.48061782e-02,  2.68636942e-02,  7.90570676e-02,\n",
       "        -5.06837033e-02,  9.49366426e-04, -2.92644463e-02,\n",
       "        -7.47172609e-02,  2.59905327e-02, -2.93541321e-04,\n",
       "         7.60727450e-02,  1.87528841e-02,  1.83859374e-02,\n",
       "        -7.27422116e-03,  4.61747982e-02,  1.58346305e-03,\n",
       "         2.65821964e-02, -2.33142748e-02, -3.69676836e-02,\n",
       "        -7.26887863e-03, -7.30943903e-02,  6.34948956e-03,\n",
       "         5.34140542e-02,  4.42199521e-02,  6.82861432e-02,\n",
       "        -1.52620748e-02,  9.11381654e-03, -1.25176245e-02,\n",
       "        -2.58776862e-02,  6.86303899e-02, -7.30535164e-02,\n",
       "         5.35669811e-02, -4.78193089e-02, -1.34955645e-02,\n",
       "        -7.64554814e-02,  6.47866875e-02,  1.68423224e-02,\n",
       "         6.16167560e-02, -3.71670872e-02, -1.43072419e-02,\n",
       "        -5.06544299e-02, -6.35677855e-03, -1.55530851e-02,\n",
       "         2.00039893e-02,  1.47641273e-02, -4.91882414e-02,\n",
       "         1.32773789e-02, -2.52844915e-02,  5.38430288e-02,\n",
       "        -1.00300768e-02, -6.02086559e-02, -3.57112214e-02,\n",
       "         2.52028909e-02, -8.05118978e-02,  7.41659431e-03,\n",
       "        -1.80075355e-02, -1.10445917e-02,  2.19048839e-02,\n",
       "        -4.77717854e-02,  7.86795393e-02, -4.46985811e-02,\n",
       "        -3.57412361e-02,  2.56313514e-02,  1.91417651e-03,\n",
       "        -6.08777292e-02, -1.18133018e-03,  1.42250741e-02,\n",
       "        -4.63669412e-02,  4.32623783e-03,  2.51366515e-02,\n",
       "         5.67832589e-03,  7.50844833e-03,  4.96631674e-03,\n",
       "         5.84728681e-02,  3.43527421e-02,  9.17416159e-03,\n",
       "         1.78250428e-02, -4.45382595e-02, -7.22035021e-02,\n",
       "         2.08048299e-02, -3.79791148e-02, -6.17735535e-02,\n",
       "         1.21624116e-02,  3.26904729e-02, -6.61537796e-02,\n",
       "         2.76100766e-02, -2.49228030e-02, -2.61835307e-02,\n",
       "         1.14236744e-02, -3.70034911e-02,  6.20969534e-02,\n",
       "        -1.79689340e-02,  3.71837430e-02,  2.94874776e-02,\n",
       "        -6.94798529e-02, -5.33128083e-02, -6.83208108e-02,\n",
       "         6.72068149e-02,  4.74398062e-02, -5.86671308e-02,\n",
       "         3.38115469e-02, -8.49760976e-03,  5.47851995e-02,\n",
       "        -2.27877852e-02, -8.42268541e-02, -6.83942363e-02,\n",
       "        -5.61398035e-03,  2.29188129e-02, -5.24892248e-02,\n",
       "        -3.75244059e-02,  2.97620054e-02,  4.19035442e-02,\n",
       "        -8.53464752e-02, -7.10017681e-02,  5.34864441e-02,\n",
       "        -4.72525060e-02,  1.31119657e-02,  8.28817785e-02,\n",
       "         2.00505350e-02, -8.10207427e-03,  2.79124919e-02,\n",
       "         5.02485074e-02, -5.69792166e-02, -3.72251794e-02,\n",
       "         6.76150173e-02,  3.79497968e-02,  3.60888802e-02,\n",
       "         2.41702981e-02, -4.17381451e-02,  3.88062298e-02,\n",
       "        -5.40836044e-02,  1.57873537e-02,  3.81499715e-02,\n",
       "         2.55523603e-02, -3.10201589e-02, -4.62461822e-02,\n",
       "        -5.27143106e-02, -8.02659318e-02, -2.68076789e-02,\n",
       "        -3.12783048e-02, -2.54059713e-02, -5.06569594e-02,\n",
       "        -1.68086626e-02,  5.79036772e-02,  2.40126867e-02,\n",
       "         2.30644085e-03, -1.87533908e-02, -7.25098029e-02,\n",
       "        -7.39663541e-02,  1.60035715e-02, -4.31297421e-02,\n",
       "         4.81103081e-03,  7.52688348e-02,  4.76829037e-02,\n",
       "        -1.23696430e-02,  1.36878574e-02, -4.76415902e-02,\n",
       "        -6.57471269e-02,  4.83493283e-02, -1.12879453e-02,\n",
       "         1.19418297e-02, -6.10471591e-02, -4.94034903e-05,\n",
       "        -6.96596876e-03,  1.73802022e-02,  4.92055863e-02,\n",
       "         6.01144060e-02,  8.82215612e-03,  7.45653175e-03,\n",
       "         3.23349684e-02,  5.86529262e-02,  5.80041409e-02,\n",
       "        -4.69943061e-02, -7.63266459e-02,  7.89773911e-02,\n",
       "         5.98765761e-02,  6.29325807e-02, -4.00616564e-02,\n",
       "        -5.65833561e-02, -3.94258089e-02,  3.17362472e-02,\n",
       "         3.93995978e-02, -7.55359828e-02, -1.85841564e-02,\n",
       "        -8.24745074e-02,  7.62508512e-02, -5.26598766e-02,\n",
       "         5.63041903e-02,  6.30326048e-02, -8.58315546e-03,\n",
       "         2.85780653e-02,  5.38281687e-02,  1.62195787e-02,\n",
       "        -5.78964734e-03, -2.33127829e-02,  5.17560227e-04,\n",
       "         8.53599701e-03,  6.80652559e-02, -2.17271876e-02,\n",
       "         3.72232660e-03, -7.24396631e-02, -3.48465145e-02,\n",
       "         1.07009299e-02, -5.61348461e-02, -4.53009196e-02,\n",
       "        -4.08716202e-02, -5.91455400e-02, -1.40004708e-02,\n",
       "         4.54916507e-02,  1.58880686e-03, -2.56779343e-02,\n",
       "         3.66247408e-02, -6.62954350e-04,  3.08912154e-02,\n",
       "        -3.48471776e-02, -6.36110678e-02, -1.30180130e-02,\n",
       "        -1.03479614e-02,  4.40291539e-02, -6.28609136e-02,\n",
       "        -1.46192033e-02,  3.01824473e-02, -5.87676056e-02,\n",
       "         6.35363907e-02,  7.12828413e-02, -3.78707238e-02,\n",
       "         2.21151374e-02,  2.17805225e-02, -1.76820457e-02,\n",
       "        -6.17579967e-02, -5.95729910e-02, -3.44189480e-02,\n",
       "        -1.30476095e-02,  6.67989627e-02,  1.36328256e-02,\n",
       "         4.47590388e-02,  1.45258596e-02, -2.90759876e-02,\n",
       "         4.19268571e-02,  5.59049807e-02, -7.04446882e-02,\n",
       "         5.69321448e-03,  3.44740809e-03, -2.26908028e-02,\n",
       "         4.38551456e-02,  8.29397663e-02, -5.30164316e-02,\n",
       "        -2.03259359e-03,  3.81756350e-02,  3.43979113e-02,\n",
       "         4.47361432e-02, -3.83217111e-02, -1.21327136e-02,\n",
       "        -2.29897480e-02, -3.42034101e-02, -6.38987124e-02,\n",
       "        -1.50330095e-02,  3.35956085e-03,  6.30215034e-02,\n",
       "        -3.95405032e-02,  3.29606943e-02, -6.96315393e-02,\n",
       "        -5.57748340e-02,  8.02816972e-02,  7.26948604e-02,\n",
       "        -5.94826266e-02,  7.47539029e-02,  4.12557796e-02,\n",
       "         3.25780958e-02,  5.15712574e-02,  7.10622743e-02,\n",
       "         6.39109872e-03,  4.97575440e-02,  6.65388594e-04,\n",
       "        -8.15524384e-02,  4.78947461e-02,  2.78505776e-03,\n",
       "         1.55665511e-02, -5.82168577e-03,  9.09321103e-03,\n",
       "         1.40138036e-02,  3.96141745e-02, -6.02626018e-02,\n",
       "         7.97180906e-02, -4.76316027e-02,  5.78116300e-03,\n",
       "        -2.99901627e-02, -4.29022722e-02,  5.11667654e-02,\n",
       "         3.96258645e-02, -8.41299370e-02,  3.90922138e-03,\n",
       "         3.42288651e-02, -3.91471907e-02, -1.63182113e-02,\n",
       "        -4.27880976e-03,  6.24184050e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_embedding_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_use_feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building a model and fitting an NLP feature extraction from tensorflow hub\n",
    "inputs = tf.keras.layers.Input(shape=(), \n",
    "                               dtype=tf.string)\n",
    "x = sentence_encoder_layer(inputs) # tokenize text and create embedding of each sequence (512 long vector)\n",
    "x = tf.keras.layers.Dense(128, \n",
    "                          activation='relu')(x)\n",
    "# if you could add more layers here if you wanted to\n",
    "outputs = tf.keras.layers.Dense(num_classes, \n",
    "                                activation='softmax')(x)\n",
    "model_2 = tf.keras.Model(inputs, \n",
    "                         outputs, \n",
    "                         name='model_2_use_feature_extractor')\n",
    "model_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 11s 14ms/step - loss: 0.9160 - accuracy: 0.6531 - val_loss: 0.7947 - val_accuracy: 0.6898\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.7667 - accuracy: 0.7028 - val_loss: 0.7502 - val_accuracy: 0.7045\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.7463 - accuracy: 0.7151 - val_loss: 0.7303 - val_accuracy: 0.7197\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_2_history = model_2.fit(train_dataset,\n",
    "                              epochs=3,\n",
    "                              steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 11s 12ms/step - loss: 0.7343 - accuracy: 0.7183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7343406677246094, 0.7182576656341553]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 11s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "model_2_pred_prob = model_2.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pred prob to classes\n",
    "model_2_preds = tf.argmax(model_2_pred_prob, axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0_results</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1_results</th>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.784934</td>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.785785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2_results</th>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.718763</td>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.715465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall        f1\n",
       "model_0_results  0.721832   0.718647  0.721832  0.698925\n",
       "model_1_results  0.787998   0.784934  0.787998  0.785785\n",
       "model_2_results  0.718258   0.718763  0.718258  0.715465"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = calculate_results(y_true=val_labels_label_encoded, y_pred=model_2_preds)\n",
    "\n",
    "model_results = pd.DataFrame({'model_0_results': model_0_results,\n",
    "                              'model_1_results': model_1_results,\n",
    "                              'model_2_results': model_2_results})\n",
    "model_results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Conv1D with character embeending\n",
    "\n",
    "The paper  which we're replicationg states they used a combination of token and character-level embeddings.\n",
    "\n",
    "Previously we've token-level embeddings but we'll nedd to do similar steps for characters if we want to use char-level embeddings.\n",
    "\n",
    "see: https://medium.com/@WojtekFulmyk/text-tokenization-and-vectorization-in-nlp-ac5e3eb35b85\n",
    "\n",
    "see: https://www.kaggle.com/code/parulpandey/getting-started-with-nlp-feature-vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make functions to split sentences into characters\n",
    "def split_chars(text:str):\n",
    "    return ' '.join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessor(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets,remove links,remove special characters\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r e c r u i t m e n t   a n d   r e t e n t i o n   r a t e s   w e r e   h i g h e r   i n   t h e   h y p e r t e n s i o n   t r i a l   t h a n   i n   t h e   d e p r e s s i o n   t r i a l   .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text splitting no-character-level sequence into characteres\n",
    "split_chars(random_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
       " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split sequence-level data splits into character-level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the average character length?\n",
    "chars_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_chars_lens = np.mean(chars_lens)\n",
    "mean_chars_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the distribution of our sequences at a character-level\n",
    "ax = plt.hist(chars_lens, bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find what character length cover 95% of sequence\n",
    "output_seq_char_len = int(np.percentile(chars_lens, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all character\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHAR_TOKENS = len(alphabet) + 2 # add 2 for space and OOV token (OOV = out of vocab, '[UNK]')\n",
    "char_vectorizer = tf.keras.layers.TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
    "                                                    output_sequence_length=output_seq_char_len,\n",
    "                                                    # standardize='lower_and_strip_punctuation', # set to None if want to leave punctuation in\n",
    "                                                    name='char_vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(analyzer='char',\n",
    "                                    ngram_range=(2, 2), \n",
    "                                    strip_accents='ascii',\n",
    "                                    max_features=output_seq_char_len).fit(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' !', ' \"', ' #', ' $', ' %'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer.get_feature_names_out()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02857339, 0.0311017 , 0.01692195, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02819855, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25555084, 0.02315991, 0.10625941,\n",
       "        0.13970839, 0.25552104, 0.11887099, 0.        , 0.09251046,\n",
       "        0.25608796, 0.        , 0.        , 0.1603618 , 0.09457417,\n",
       "        0.15349753, 0.20583653, 0.05576017, 0.05281096, 0.17040225,\n",
       "        0.15374071, 0.23783282, 0.11257438, 0.        , 0.04113893,\n",
       "        0.08315216, 0.06411402, 0.04750782, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02857283, 0.03109713, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02812691, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25539475, 0.02297146, 0.10608997,\n",
       "        0.1395881 , 0.25548272, 0.11825995, 0.        , 0.0922827 ,\n",
       "        0.25584768, 0.        , 0.        , 0.16027708, 0.09426594,\n",
       "        0.15323174, 0.20575308, 0.0554447 , 0.05259706, 0.17036628,\n",
       "        0.1536929 , 0.2545719 , 0.11243551, 0.        , 0.04062365,\n",
       "        0.08312711, 0.06410375, 0.04748602, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice = random.choice(train_chars)\n",
    "x = tf_idf_vectorizer.transform([choice]).toarray()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2),\n",
       "                preprocessor=<function custom_preprocessor at 0x000001A7B2725730>,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# World level unigrams and bigrams\n",
    "count_vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                   preprocessor=custom_preprocessor, \n",
    "                                   ngram_range=(1,2),\n",
    "                                   min_df=2,\n",
    "                                   max_df=0.8)\n",
    "count_vectorizer.fit(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['investigate', 'efficacy', 'weeks', 'daily', 'low']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character level bigrams\n",
    "count_vectorizer = CountVectorizer(preprocessor=custom_preprocessor,\n",
    "                                   stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                   ngram_range=(2,2),\n",
    "                                   max_features=output_seq_char_len,\n",
    "                                   strip_accents='ascii',\n",
    "                                   analyzer='char_wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  4,  8,  5, 19,  6,  3,  5, 19,  1,  6,  3, 13, 12,  7, 11,\n",
       "         7, 15,  4,  4,  3,  1, 10,  4,  8,  5, 19,  6,  3,  5, 19,  1,\n",
       "         6,  3, 13, 12,  7, 11,  7, 15,  4,  4,  3,  1]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors = count_vectorizer.fit_transform([random.choice(train_chars)])\n",
    "train_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt character vectorizer to training\n",
    "char_vectorizer.adapt(train_chars)\n",
    "# test_vectors = count_vectorizer.transform(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 28\n",
      "5 most common char: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 lear common char: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# check vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f'Number of different characters in character vocab: {len(char_vocab)}')\n",
    "print(f'5 most common char: {char_vocab[:5]}')\n",
    "print(f'5 lear common char: {char_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 44\n",
      "5 most common char: [' t', 't ', ' a', 'a ', ' c']\n",
      "5 lear common char: ['v ', ' p', 'p ', ' g', 'g ']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of different characters in character vocab: {len(list(count_vectorizer.vocabulary_))}')\n",
    "print(f'5 most common char: {list(count_vectorizer.vocabulary_)[:5]}')\n",
    "print(f'5 lear common char: {list(count_vectorizer.vocabulary_)[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "t h e   m e f e n a m i c   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   e v e r y   @   h   ,   a n d   t h e   g i n g e r   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   (   z i n t o m a   )   e v e r y   @   h   f r o m   t h e   o n s e t   o f   m e n s t r u a t i o n   u n t i l   p a i n   r e l i e f   l a s t e d   @   c y c l e s   .\n",
      "\n",
      "Length of character: 151\n",
      "\n",
      "Vectorized Vector: [[ 3 13  2 15  2 17  2  6  5 15  4 11 18  8  7 16 14  8  2 11  2  4 21  2\n",
      "  10 15 18 11  5 14  9 16 12  2  9  2 21  2  8 19 13  5  6 10  3 13  2 18\n",
      "   4  6 18  2  8 18  8  7 16 14  8  2 11  2  4 21  2 10 15 18 11  5 14  9\n",
      "  16 12  2  9 25  4  6  3  7 15  5  2 21  2  8 19 13 17  8  7 15  3 13  2\n",
      "   7  6  9  2  3  7 17 15  2  6  9  3  8 16  5  3  4  7  6 16  6  3  4 12\n",
      "  14  5  4  6  8  2 12  4  2 17 12  5  9  3  2 10 11 19 11 12  2  9  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Shape of vectorized chars: (1, 290)\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f'Charified text:\\n{random_train_chars}')\n",
    "print(f'\\nLength of character: {len(random_train_chars.split())}')\n",
    "\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "vectorized_chars_counter = count_vectorizer.fit_transform([random_train_chars])\n",
    "\n",
    "print(f'\\nVectorized Vector: {vectorized_chars}')\n",
    "# print(f'\\nLength of vectorized chars: {len(vectorized_chars[0])}')\n",
    "print(f'\\nShape of vectorized chars: {vectorized_chars.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "t h e   m e f e n a m i c   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   e v e r y   @   h   ,   a n d   t h e   g i n g e r   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   (   z i n t o m a   )   e v e r y   @   h   f r o m   t h e   o n s e t   o f   m e n s t r u a t i o n   u n t i l   p a i n   r e l i e f   l a s t e d   @   c y c l e s   .\n",
      "\n",
      "Length of character: 151\n",
      "\n",
      "Vectorized Counter: [[ 8.  7.  4. 24.  4.  6.  5.  9.  6.  7.  9.  7.  5. 10.  8.  9.  6.  4.\n",
      "   3.  1.  8.  7.  4. 24.  4.  6.  5.  9.  6.  7.  9.  7.  5. 10.  8.  9.\n",
      "   6.  4.  3.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n",
      "\n",
      "Shape of vectorized chars: (1, 290)\n"
     ]
    }
   ],
   "source": [
    "print(f'Charified text:\\n{random_train_chars}')\n",
    "print(f'\\nLength of character: {len(random_train_chars.split())}')\n",
    "vectorized_chars_counter = count_vectorizer.fit_transform([random_train_chars])\n",
    "\n",
    "# https://stackoverflow.com/questions/12668027/good-ways-to-expand-a-numpy-ndarray\n",
    "vectorized_chars_counter_array = np.hstack((vectorized_chars_counter.toarray()[0], \n",
    "                                            np.zeros(output_seq_char_len - len(vectorized_chars_counter.toarray()[0])))).reshape(1, -1)\n",
    "print(f'\\nVectorized Counter: {vectorized_chars_counter_array}')\n",
    "# print(f'\\nLength of vectorized chars: {vectorized_chars_counter.getnnz()}')\n",
    "print(f'\\nShape of vectorized chars: {vectorized_chars_counter_array.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297.7325149966674"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(char) for char in train_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297.27229999998235"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(sentence) for sentence in train_sentences], 95.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_vocab) # alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed_keras = tf.keras.layers.Embedding(input_dim=len(char_vocab), # size of vocabulary\n",
    "                                             output_dim=25, # this is the size of the char embedding in the paper\n",
    "                                             mask_zero=True,\n",
    "                                             name='char_embed_keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "t h e   m e f e n a m i c   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   e v e r y   @   h   ,   a n d   t h e   g i n g e r   g r o u p   r e c e i v e d   @   m g   c a p s u l e s   (   z i n t o m a   )   e v e r y   @   h   f r o m   t h e   o n s e t   o f   m e n s t r u a t i o n   u n t i l   p a i n   r e l i e f   l a s t e d   @   c y c l e s   .\n",
      "\n",
      "Charified text:151\n",
      "\n",
      "Vectorized Vector: [[[ 0.00405673 -0.0102626  -0.00928537 ...  0.01798593  0.01154329\n",
      "   -0.04663555]\n",
      "  [ 0.04178281  0.01237445  0.03321778 ... -0.03518739 -0.03931598\n",
      "    0.01076182]\n",
      "  [-0.02903293 -0.00401677 -0.02034562 ...  0.01231202  0.03038951\n",
      "    0.0423291 ]\n",
      "  ...\n",
      "  [ 0.00661986  0.04478389 -0.01604369 ... -0.00827882  0.02005162\n",
      "    0.02211894]\n",
      "  [ 0.00661986  0.04478389 -0.01604369 ... -0.00827882  0.02005162\n",
      "    0.02211894]\n",
      "  [ 0.00661986  0.04478389 -0.01604369 ... -0.00827882  0.02005162\n",
      "    0.02211894]]]\n",
      "\n",
      "Shape of vectorized chars: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "print(f'Charified text:\\n{random_train_chars}')\n",
    "\n",
    "print(f'\\nCharified text:{len(random_train_chars.split())}')\n",
    "char_embed_keras_sample = char_embed_keras(char_vectorizer([random_train_chars]))\n",
    "\n",
    "print(f'\\nVectorized Vector: {char_embed_keras_sample}')\n",
    "print(f'\\nShape of vectorized chars: {char_embed_keras_sample.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see: https://towardsdatascience.com/word-embedding-techniques-word2vec-and-tf-idf-explained-c5d02e34d08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_train_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Conv1D model and fit with character-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_conv1d_char_embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " char_vectorizer (TextVector  (None, 290)              0         \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " char_embed_keras (Embedding  (None, 290, 25)          700       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 290, 64)           8064      \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make Conv1D on chars\n",
    "inputs = tf.keras.layers.Input(shape=(1,), \n",
    "                               dtype=tf.string)\n",
    "x = char_vectorizer(inputs)\n",
    "x = char_embed_keras(x)\n",
    "x = tf.keras.layers.Conv1D(filters=64, \n",
    "                           kernel_size=5, \n",
    "                           padding='same', \n",
    "                           activation='relu')(x)\n",
    "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, \n",
    "                                activation='softmax')(x)\n",
    "model_3 = tf.keras.Model(inputs=inputs, \n",
    "                         outputs=outputs,\n",
    "                         name='model_3_conv1d_char_embedding')\n",
    "\n",
    "model_3.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, \n",
    "                                                         train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, \n",
    "                                                       val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, \n",
    "                                                        test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 6s 9ms/step - loss: 1.2463 - accuracy: 0.4807 - val_loss: 1.0673 - val_accuracy: 0.5851\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 3s 6ms/step - loss: 1.0985 - accuracy: 0.5504 - val_loss: 0.9831 - val_accuracy: 0.6127\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 3s 6ms/step - loss: 1.0124 - accuracy: 0.5968 - val_loss: 0.9056 - val_accuracy: 0.6556\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/945 [..............................] - ETA: 16s - loss: 1.5518 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 4ms/step - loss: 0.9608 - accuracy: 0.6206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9608335494995117, 0.6206474304199219]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/945 [..............................] - ETA: 14s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1_results</th>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.784934</td>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.785785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_0_results</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2_results</th>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.718763</td>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.715465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_results</th>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.642904</td>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.639734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall        f1\n",
       "model_1_results  0.787998   0.784934  0.787998  0.785785\n",
       "model_0_results  0.721832   0.718647  0.721832  0.698925\n",
       "model_2_results  0.718258   0.718763  0.718258  0.715465\n",
       "model_3_results  0.652621   0.642904  0.652621  0.639734"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds_prob = model_3.predict(val_char_dataset)\n",
    "model_3_preds = tf.argmax(model_3_preds_prob, \n",
    "                          axis=1)\n",
    "\n",
    "model_3_results = calculate_results(y_true=val_labels_label_encoded, \n",
    "                                    y_pred=model_3_preds)\n",
    "\n",
    "model_results = pd.DataFrame({'model_0_results': model_0_results,\n",
    "                              'model_1_results': model_1_results,\n",
    "                              'model_2_results': model_2_results,\n",
    "                              'model_3_results': model_3_results})\n",
    "\n",
    "model_results.transpose().sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Combine pretrained token embedding + characteres (hydrid)\n",
    "\n",
    "1. Create a token level embedding (similar model 1)\n",
    "2. create a character-level (similar model 3)\n",
    "3. Combine 1 & 2 model witch concatenate (layers.concatenate)\n",
    "4. Build a series of output layers on top  of 3 similar\n",
    "5. Construct a model which takes token and caracter-level sequences as input and produces sequence label probabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup token inputs/model\n",
    "token_inputs =  tf.keras.layers.Input(shape=(), \n",
    "                                      dtype=tf.string, \n",
    "                                      name='token_input')\n",
    "\n",
    "token_embeddings = sentence_encoder_layer(token_inputs)\n",
    "\n",
    "token_output = tf.keras.layers.Dense(units=128, \n",
    "                                     activation='relu')(token_embeddings)\n",
    "\n",
    "token_model = tf.keras.Model(token_inputs, token_output, name='token_model')\n",
    "\n",
    "# 2. Setup character inputs/model\n",
    "char_inputs = tf.keras.Input(shape=(1,),\n",
    "                              dtype=tf.string,\n",
    "                              name='char_input')\n",
    "\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed_keras(char_vectors)\n",
    "char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(25))(char_embeddings) # bi-LSTM shown in figure 1 of https://arxiv.org/abs/1710.06071\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm,\n",
    "                            name='char_model')\n",
    "\n",
    "# 3. Setup concatenate token and char inputs/model\n",
    "token_char_concat = tf.keras.layers.Concatenate(name='token_char_hydrid')([token_model.output, \n",
    "                                                                           char_model.output])\n",
    "\n",
    "# 4. create output layers - adding in Dropout, discussed in section 4.2 of https://arxiv.org/abs/1710.06071\n",
    "combined_dropout = tf.keras.layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = tf.keras.layers.Dense(128, \n",
    "                                       activation='relu')(combined_dropout)\n",
    "final_dropout = tf.keras.layers.Dropout(0.6)(combined_dense)\n",
    "output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(final_dropout)\n",
    "\n",
    "# 5. Construct model with char and token input/model\n",
    "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input], outputs=output_layer, name='model_4_token_and_char_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_token_and_char_embeddings\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_input (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " USE (KerasLayer)               (None, 512)          256797824   ['token_input[0][0]']            \n",
      "                                                                                                  \n",
      " char_embed_keras (Embedding)   (None, 290, 25)      700         ['char_vectorizer[3][0]']        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          65664       ['USE[1][0]']                    \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 50)           10200       ['char_embed_keras[3][0]']       \n",
      "                                                                                                  \n",
      " token_char_hydrid (Concatenate  (None, 178)         0           ['dense_6[0][0]',                \n",
      " )                                                                'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 178)          0           ['token_char_hydrid[0][0]']      \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          22912       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 5)            645         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,897,945\n",
      "Trainable params: 100,121\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# plot the model\n",
    "plot_model(model_4, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# model_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.SGD(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining token and character data into tf.data dataset\n",
    "\n",
    "see: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine chars and token\n",
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combile data and labels\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # prefetch and batch dataset\n",
    "\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # prefetch and batch dataset\n",
    "\n",
    "test_char_token_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_chars))\n",
    "test_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "test_char_token_dataset = tf.data.Dataset.zip((test_char_token_data, test_char_token_labels))\n",
    "test_char_token_dataset = test_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # prefetch and batch dataset\n",
    "\n",
    "\n",
    "train_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 62s 85ms/step - loss: 1.4996 - accuracy: 0.3537 - val_loss: 1.4432 - val_accuracy: 0.4385\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 46s 82ms/step - loss: 1.4372 - accuracy: 0.4037 - val_loss: 1.4055 - val_accuracy: 0.4734\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 41s 73ms/step - loss: 1.4020 - accuracy: 0.4349 - val_loss: 1.3478 - val_accuracy: 0.4910\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 47s 83ms/step - loss: 1.3397 - accuracy: 0.4590 - val_loss: 1.2723 - val_accuracy: 0.5010\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 43s 76ms/step - loss: 1.2834 - accuracy: 0.4765 - val_loss: 1.1920 - val_accuracy: 0.5126\n"
     ]
    }
   ],
   "source": [
    "# fit the model 4\n",
    "# fit the model\n",
    "model_4_history = model_4.fit(train_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
    "                              epochs=5,\n",
    "                              validation_data=val_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48/945 [>.............................] - ETA: 35s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 35s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\tensorflow_certificate\\.tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1_results</th>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.784934</td>\n",
       "      <td>0.787998</td>\n",
       "      <td>0.785785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_0_results</th>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2_results</th>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.718763</td>\n",
       "      <td>0.718258</td>\n",
       "      <td>0.715465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_results</th>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.642904</td>\n",
       "      <td>0.652621</td>\n",
       "      <td>0.639734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4_results</th>\n",
       "      <td>0.519396</td>\n",
       "      <td>0.456979</td>\n",
       "      <td>0.519396</td>\n",
       "      <td>0.421532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall        f1\n",
       "model_1_results  0.787998   0.784934  0.787998  0.785785\n",
       "model_0_results  0.721832   0.718647  0.721832  0.698925\n",
       "model_2_results  0.718258   0.718763  0.718258  0.715465\n",
       "model_3_results  0.652621   0.642904  0.652621  0.639734\n",
       "model_4_results  0.519396   0.456979  0.519396  0.421532"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds_prob = model_4.predict(val_char_token_dataset)\n",
    "model_4_preds = tf.argmax(model_4_preds_prob, \n",
    "                          axis=1)\n",
    "\n",
    "model_4_results = calculate_results(y_true=val_labels_label_encoded, \n",
    "                                    y_pred=model_4_preds)\n",
    "\n",
    "model_results = pd.DataFrame({'model_0_results': model_0_results,\n",
    "                              'model_1_results': model_1_results,\n",
    "                              'model_2_results': model_2_results,\n",
    "                              'model_3_results': model_3_results,\n",
    "                              'model_4_results': model_4_results})\n",
    "\n",
    "model_results.transpose().sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Pretrained token embeddings + character embeddings + positional embeddings\n",
    "\n",
    "## Feature Engineering\n",
    "* Taking `non-obvious features` from the data and encoding them numerically to help our model learn\n",
    "* How can we add extra sources of data to our model?\n",
    "\n",
    "Data augmentation is a form of feature engineering\n",
    "\n",
    "> **Note**: Any engineered features used to train a model need to be available at test time.  \n",
    "> In our case, line numbers and total line are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: number, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many different line numbers are there?\n",
    "train_df['number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>number</th>\n",
       "      <th>total_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...       0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...       1   \n",
       "2    METHODS  outcome measures included pain reduction and i...       2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...       3   \n",
       "4    METHODS  secondary outcome measures included the wester...       4   \n",
       "\n",
       "   total_line  \n",
       "0          11  \n",
       "1          11  \n",
       "2          11  \n",
       "3          11  \n",
       "4          11  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check distribution of number\n",
    "train_df.number.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 15), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " TensorShape([180040, 15]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorflow one-hot-encoder to create tensors of our number column\n",
    "train_line_numbers_one_hot = tf.one_hot(train_df['number'].to_numpy(), depth=15) # depth=15 to prevent large dimension \n",
    "val_line_numbers_one_hot = tf.one_hot(val_df['number'].to_numpy(), depth=15) # depth=15 to prevent large dimension \n",
    "test_line_numbers_one_hot = tf.one_hot(test_df['number'].to_numpy(), depth=15) # depth=15 to prevent large dimension \n",
    "\n",
    "train_line_numbers_one_hot[:10], train_line_numbers_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've encoded our line numbers feature. let's do the same for our total lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  7.,  4., 24.,  4.,  6.,  5.,  9.,  6.,  7.,  9.,  7.,  5.,\n",
       "        10.,  8.,  9.,  6.,  4.,  3.,  1.,  8.,  7.,  4., 24.,  4.,  6.,\n",
       "         5.,  9.,  6.,  7.,  9.,  7.,  5., 10.,  8.,  9.,  6.,  4.,  3.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_features=25)\n",
    "vectorized_chars_counter = count_vectorizer.fit_transform([random_train_chars])\n",
    "vectorized_chars_counter_array = np.hstack((vectorized_chars_counter.toarray()[0], \n",
    "                                            np.zeros(output_seq_char_len - len(vectorized_chars_counter.toarray()[0])))).reshape(1, -1)\n",
    "\n",
    "vectorized_chars_counter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(max_features=25,\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    strip_accents='ascii',\n",
    "                                    analyzer='char_wb')\n",
    "char_embed_tf_idf = tf_idf_vectorizer.fit_transform(np.hstack((random_train_chars.split(), \n",
    "                                                               np.zeros(output_seq_char_len - len(random_train_chars.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<290x25 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 717 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_embed_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'numpy.str_'>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7058, 56800)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "vocabs = np.hstack((random_train_chars.split(),\n",
    "                    np.zeros(output_seq_char_len - len(random_train_chars.split()))))\n",
    "w2v_model = Word2Vec(min_count=4,\n",
    "                     window=4,\n",
    "                     vector_size=len(vocabs),\n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     sg = 1,\n",
    "                     workers=cores-1)\n",
    "w2v_model.build_vocab(vocabs, progress_per=10000)\n",
    "w2v_model.train(vocabs, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 290)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('D:/txt/cbow_s1000.txt', 'r', encoding='utf-8') as f:\n",
    "#     lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in lines[1:10]:\n",
    "#     print(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('input', help='Single embedding txt file')\n",
    "# parser.add_argument('output', help='Output basename without extension')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# embedding_cbow_file = args.ouput + '.npy'\n",
    "# vocabulary_cbow_file = args.output + '.txt'\n",
    "\n",
    "# https://blog.ekbana.com/loading-glove-pre-trained-word-embedding-model-from-text-file-faster-5d3e8f2b8455\n",
    "# https://gist.github.com/erickrf/e54cd0f3d917ec61b3ae758a5e47b883\n",
    "# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "# https://medium.com/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1\n",
    "# https://github.com/deeplearning4j\n",
    "# https://medium.com/@erkajalkumari/step-by-step-guide-to-word2vec-with-gensim-2c4cd9dde01f\n",
    "\n",
    "# vocabs = []\n",
    "# words_vector = []\n",
    "# for line in lines[1:100]:\n",
    "#     splitlines = line.split()\n",
    "#     vocabs.append(splitlines[0].strip())\n",
    "#     words_vector.append(np.fromiter((np.float32(x.replace(',', '.')) for x in splitlines[1:]), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('D:/txt/cbow_1000.npy', np.array(words_vector))\n",
    "# with open('D:/txt/cbow_1000.vocab', 'w', encoding='utf-8') as f:\n",
    "#     for vocab in vocabs:\n",
    "#         f.write(vocab)\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(input_txt, output_vocab, output_binary):\n",
    "    \"\"\"\n",
    "    :param input_txt - takes path of embedding which is in text format\n",
    "    :param output_vocab - output vocabulary\n",
    "    :param output_binary - output numpy array binary \n",
    "    :return a binary file Numpy .npy format\n",
    "    \"\"\"\n",
    "    with open(input_txt, 'r', encoding='utf-8') as read_file:\n",
    "        lines = read_file.readlines()\n",
    "        word_vector = []\n",
    "        with open(output_vocab, 'w', encoding='utf-8') as write_file:\n",
    "            for line in lines[1:100]:\n",
    "                splitlines = line.split()\n",
    "                write_file.write(splitlines[0].strip().encode('utf-8'))\n",
    "                write_file.write(\"\\n\")\n",
    "                word_vector.append(np.fromiter((np.float32(x.replace(',', '.')) for x in splitlines[1:]), dtype=np.float32))\n",
    "    np.save(output_binary, np.array(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_binary():\n",
    "    \"\"\"\n",
    "    encoding='cp1252'\n",
    "    It loads embedding provided by glove which is saved as binary file. Loading of this model is\n",
    "    about  second faster than that of loading of txt glove file as model.\n",
    "    :param embeddings_path: path of glove file.\n",
    "    :return: glove model\n",
    "    \"\"\"\n",
    "    model = {}\n",
    "\n",
    "    with open('D:/txt/cbow_1000.vocab', 'r', encoding='utf-8') as file:\n",
    "        words = [line.strip() for line in file]\n",
    "    \n",
    "    wv = np.load('D:/txt/cbow_1000.npy')\n",
    "    \n",
    "    for i, w in enumerate(words):\n",
    "        model[w] = wv[i]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_phrases(sentences):\n",
    "    phrases = Phrases(sentences,\n",
    "                      min_count=5,\n",
    "                      threshold=7,\n",
    "                      progress_per=1000)\n",
    "    return Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = build_phrases([\"hoje  bonito\", \"amanh ser feito\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_w2v = load_embeddings_binary()\n",
    "# embedding_df = pd.DataFrame(dict_w2v)\n",
    "# embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v(sentence, model):\n",
    "    \"\"\"\n",
    "    :param sentence: inputs a single sentences whose word embedding is to be extracted.\n",
    "    :param model: inputs glove model.\n",
    "    :return: returns numpy array containing word embedding of all words    in input sentence.\n",
    "    \"\"\"\n",
    "    return np.array([model.get(val, np.zeros(1000)) for val in sentence.split()], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sentences = [\"oi me ferrei!\"]\n",
    "model_w2v = Word2Vec(sentences=[sentence.split() for sentence in w2v_sentences], \n",
    "                     vector_size=1000,\n",
    "                     min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    }
   ],
   "source": [
    "model_w2v.build_vocab([sentence.split() for sentence in w2v_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01410555,  0.00464589, -0.01393688, ..., -0.04186802,\n",
       "        -0.0317688 ,  0.00677336],\n",
       "       [ 0.03794698, -0.00839328,  0.04254368, ...,  0.0391486 ,\n",
       "         0.02925768,  0.04951321],\n",
       "       [-0.00294314,  0.00129767,  0.02801025, ...,  0.03203147,\n",
       "         0.05154461,  0.01924811]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.get_normed_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.57017615e-04,  8.46529001e-05, -2.53944163e-04,  9.35766671e-04,\n",
       "        2.75750877e-04,  4.09564731e-04, -1.18293523e-04,  9.04502886e-05,\n",
       "        6.62430772e-04, -7.26501967e-05,  3.34150798e-04, -6.72020906e-05,\n",
       "        5.24839619e-04,  3.63993400e-04,  2.58252869e-04, -5.30989433e-04,\n",
       "       -4.70810162e-04,  4.30802116e-04, -5.90717071e-04, -1.80206298e-05,\n",
       "       -6.33516320e-05,  3.49324226e-04, -8.44226626e-04,  8.81723419e-04,\n",
       "       -1.44874575e-04, -5.33092709e-04,  4.05446772e-04, -1.93549160e-04,\n",
       "       -7.76548404e-04, -4.49679850e-04, -3.87728214e-05, -8.94647383e-04,\n",
       "        5.70561897e-05,  2.44179246e-04, -3.22527398e-04,  2.57040025e-04,\n",
       "        2.48079770e-04,  9.98821459e-04,  1.43050434e-04,  2.02053780e-04,\n",
       "        2.77956016e-04, -2.07787278e-04, -8.69861629e-04,  8.02317401e-04,\n",
       "       -1.97469708e-04, -9.69231362e-04, -6.55200507e-04, -3.94586095e-04,\n",
       "        3.95434618e-04,  5.03858086e-04,  6.08601084e-04, -6.77026052e-04,\n",
       "        6.88836590e-05, -2.77528277e-04, -5.20919799e-04,  6.98127260e-04,\n",
       "        3.95196665e-04, -3.10650823e-04, -8.27690819e-04, -5.14078594e-04,\n",
       "       -6.49535650e-05,  7.81176321e-04,  6.04418514e-04, -8.45165749e-04,\n",
       "       -9.56353673e-04,  7.13383430e-04, -2.32756618e-04, -3.69230984e-04,\n",
       "        5.74983133e-04, -5.84430702e-04,  5.09395381e-04, -2.42426395e-05,\n",
       "       -6.87516469e-04, -3.31637857e-05,  6.35899079e-04,  9.29393747e-04,\n",
       "        2.22091199e-04,  5.05009200e-04, -4.97452507e-04, -7.97553075e-05,\n",
       "       -5.31763537e-04,  1.18896249e-04, -1.79321534e-04, -3.63263593e-04,\n",
       "       -7.01437937e-04,  9.65443149e-04,  2.97582621e-04, -2.28122473e-04,\n",
       "       -4.18409123e-04,  7.71378749e-04, -6.48185494e-04,  3.12154298e-04,\n",
       "        7.87355893e-05,  8.32288002e-04,  6.83617603e-04, -2.90864700e-04,\n",
       "        2.53509992e-04, -1.66607380e-04, -9.45466280e-04, -2.61346111e-04,\n",
       "        1.33252383e-04,  6.54085656e-04,  9.98460338e-04,  9.06245492e-04,\n",
       "       -8.01536080e-04,  6.49138470e-04, -5.71473851e-04, -9.71574773e-05,\n",
       "        4.82821451e-05,  6.58193370e-04,  4.47014318e-04,  4.60372685e-04,\n",
       "        9.48312285e-04,  3.82664221e-05, -6.03871362e-04, -6.33010175e-04,\n",
       "        6.43178937e-04, -5.24258125e-04, -2.84981244e-04,  4.07528394e-04,\n",
       "       -2.29023688e-04, -6.02521410e-04, -2.32365608e-04,  1.20691773e-04,\n",
       "        2.18335874e-04,  6.08377217e-04, -5.21400187e-04,  3.07795999e-04,\n",
       "        7.24067446e-04,  2.19511276e-04,  5.39748929e-04, -4.84533317e-04,\n",
       "        6.15261088e-04, -7.60128256e-04,  3.49286565e-04, -9.32180381e-04,\n",
       "       -2.60431058e-04, -9.07320005e-04, -1.58826835e-04, -5.36475156e-04,\n",
       "       -3.94392002e-04,  1.15365270e-04,  2.80034787e-04, -1.52639623e-04,\n",
       "       -8.17051623e-04, -5.91802353e-04,  8.19294437e-05, -3.94625909e-04,\n",
       "       -9.43044899e-04, -7.74974833e-05,  6.63326762e-04,  5.97884413e-04,\n",
       "       -9.91725945e-04,  3.11858166e-04, -5.98730112e-04, -9.18189064e-04,\n",
       "        1.70211788e-05, -3.69620320e-05, -6.97200070e-04, -6.28005771e-04,\n",
       "       -2.42608541e-04,  7.09665532e-04, -7.54587876e-04,  7.69808306e-04,\n",
       "       -4.75444795e-05,  1.09329223e-04,  9.48266010e-04,  4.72815998e-04,\n",
       "       -3.57276673e-04,  3.73561867e-04,  3.51928466e-04,  6.33669610e-04,\n",
       "        6.93392758e-06, -4.42368735e-04,  1.31827110e-04, -5.41423564e-04,\n",
       "        1.41175740e-04,  4.92618070e-04,  5.15484833e-04,  9.18163802e-04,\n",
       "       -7.51266489e-04, -5.40364475e-04,  6.46937115e-04,  1.35547874e-04,\n",
       "       -6.61180238e-04,  8.84389883e-05,  2.67704017e-04, -2.52883678e-04,\n",
       "       -4.96016000e-04,  5.00475406e-04,  9.62182065e-04, -7.36467366e-04,\n",
       "       -1.15323064e-05, -2.56445899e-04, -6.36514160e-04, -1.37865543e-04,\n",
       "       -5.25078562e-04,  9.05999448e-04, -5.79076994e-04,  3.68607522e-04,\n",
       "       -2.37486365e-05,  4.21917677e-04,  2.11414575e-04,  9.99582000e-04,\n",
       "        6.29479910e-05, -5.46442752e-04, -1.17969277e-04,  2.07053177e-04,\n",
       "       -3.37306963e-04, -7.84676813e-04, -5.59926266e-04, -6.75006886e-04,\n",
       "        6.35332603e-04,  3.92255548e-04,  8.21553462e-04,  6.51966839e-04,\n",
       "       -6.12784119e-04,  2.71594996e-04,  8.47212563e-04,  1.59565694e-04,\n",
       "        3.06822767e-04,  5.81261411e-04, -8.83937115e-04,  9.12474643e-04,\n",
       "        6.81948208e-04,  8.51044198e-04, -8.22626345e-04,  6.17553946e-04,\n",
       "        6.62907143e-04, -1.35764363e-04, -6.29386690e-04,  5.32667851e-04,\n",
       "       -6.85957901e-04, -5.32335544e-04,  3.51168885e-04,  8.08097131e-04,\n",
       "        8.69269366e-04, -4.40531498e-04, -9.18877136e-04,  9.60769423e-04,\n",
       "        6.29030692e-04, -3.96633637e-04, -8.45973031e-04, -4.71833453e-04,\n",
       "       -3.95722862e-04, -3.27345129e-04,  8.19091802e-05, -2.97162533e-05,\n",
       "       -3.11237818e-04, -5.99598861e-04,  9.42051876e-04, -4.72553744e-04,\n",
       "       -7.26209895e-04,  7.68472906e-04,  2.51769554e-04,  8.62639456e-04,\n",
       "       -4.46511753e-04, -6.89240464e-04,  9.84902363e-05, -1.17297648e-04,\n",
       "       -9.39706573e-04, -1.60307405e-04,  3.05059919e-04,  6.56578050e-04,\n",
       "        6.84524071e-04,  3.20827734e-04, -4.44327365e-04, -1.83916811e-04,\n",
       "       -3.94025788e-04,  5.77391358e-04, -6.35870907e-04,  2.10301878e-04,\n",
       "       -1.34523390e-04, -5.81277825e-04, -7.24621292e-04,  5.85256086e-04,\n",
       "       -8.35820450e-04, -6.87251086e-05,  2.82742491e-04,  7.73901003e-04,\n",
       "       -7.29790947e-04,  3.30457202e-04,  9.80849727e-04, -6.97707874e-04,\n",
       "       -3.53485812e-04,  5.13351173e-04,  5.23838506e-04,  1.62411452e-04,\n",
       "        7.97113404e-04,  8.31587313e-05,  1.87131649e-04, -1.60525087e-04,\n",
       "       -8.16627755e-04,  3.25780391e-04,  1.96636436e-04, -8.73420504e-04,\n",
       "       -6.75008268e-05,  7.66706489e-06, -5.96046448e-07,  8.71013384e-04,\n",
       "       -2.50876677e-04, -5.90265729e-04,  7.48333696e-04, -7.25973339e-04,\n",
       "       -8.96611949e-04, -1.78959366e-04, -8.36743857e-04,  3.90207751e-05,\n",
       "        1.94573397e-04, -2.46948475e-04, -6.44801126e-04, -3.21180814e-05,\n",
       "       -1.09850407e-04,  3.49336158e-04,  8.12701241e-04,  5.85556962e-04,\n",
       "        8.44098802e-04, -8.96817190e-04,  9.44248692e-04, -2.36575608e-04,\n",
       "        8.69705225e-04,  2.38461740e-04,  3.58524092e-04, -9.58168763e-04,\n",
       "       -9.48645349e-04,  8.98391940e-04, -2.89676915e-04,  2.81641725e-04,\n",
       "        6.41944178e-04, -2.99928197e-05,  9.72189649e-04, -1.03371618e-04,\n",
       "       -9.67287517e-04, -7.05484883e-04, -1.04315761e-04, -8.67490075e-04,\n",
       "        7.42144824e-04,  3.61933227e-04, -8.74694611e-04,  8.47972173e-04,\n",
       "        8.92963901e-04,  5.84736816e-04,  6.90985180e-04, -9.57091339e-04,\n",
       "        4.92467880e-05, -9.22063133e-04, -3.66601715e-04,  2.53169528e-05,\n",
       "       -2.80406475e-05,  1.46528240e-04,  3.27754271e-04,  2.12692743e-04,\n",
       "        5.31984551e-04,  7.52049440e-04, -5.88568917e-04,  7.95731554e-04,\n",
       "        5.99150662e-04,  9.78588825e-04,  4.62385651e-04, -3.32727679e-04,\n",
       "       -3.74640716e-04, -6.29124625e-05, -1.65519959e-04,  9.87258391e-04,\n",
       "        1.12320420e-04,  4.00725374e-04,  3.41855513e-04, -8.85130430e-04,\n",
       "        6.72061695e-04,  8.19102977e-04, -1.66584257e-04,  2.33345272e-04,\n",
       "       -6.47921581e-04, -6.12575503e-04,  8.21604510e-04, -3.04542074e-04,\n",
       "        6.74003153e-04,  1.55318499e-04, -1.98156355e-04,  3.05532682e-04,\n",
       "       -4.02105565e-04, -1.78543094e-04,  1.38072966e-04,  4.88718040e-04,\n",
       "       -1.40522476e-04,  6.56528500e-05, -7.93245097e-04,  9.49515554e-04,\n",
       "       -8.76255042e-04,  7.06991937e-04,  3.90513655e-04, -6.99806900e-04,\n",
       "       -5.29517885e-04, -7.93824671e-04, -5.13027888e-04,  7.07059167e-04,\n",
       "        9.64061765e-04,  2.15461259e-04,  6.40404251e-05,  9.52446950e-04,\n",
       "       -4.97356639e-04, -1.28330474e-04,  3.28063732e-04, -6.41403429e-04,\n",
       "       -9.70159075e-04, -9.26023466e-04,  9.02069558e-04,  5.37169224e-04,\n",
       "       -4.78822709e-04, -8.32964201e-04,  1.29395004e-04,  2.87806266e-04,\n",
       "       -1.24528407e-04,  1.27087114e-04, -4.32130328e-04,  4.79136477e-04,\n",
       "        1.47518396e-04,  8.87782313e-04, -9.97651368e-04, -5.26957039e-04,\n",
       "       -9.10284289e-04, -3.47919449e-05, -7.85730605e-04,  5.03123971e-04,\n",
       "       -6.39685604e-04, -5.95283753e-04,  5.07091056e-04, -8.15976877e-04,\n",
       "        1.45520215e-04, -7.23954174e-04,  9.86242085e-04,  8.63375899e-04,\n",
       "        1.76895148e-04,  5.78850275e-04,  4.59621428e-04, -5.99178311e-04,\n",
       "        9.75694682e-04, -9.68220702e-04,  8.04925687e-04,  2.75637867e-04,\n",
       "       -3.05512192e-04, -3.56186385e-04,  9.07195325e-04, -5.44090988e-04,\n",
       "        8.18687200e-04, -6.00888743e-04,  8.39137530e-04, -5.55493825e-05,\n",
       "        7.94259773e-04, -3.15497164e-04,  5.97921375e-04,  8.80434527e-04,\n",
       "        2.54383805e-04,  1.31774897e-04,  5.03919146e-04,  8.00252194e-04,\n",
       "        8.56801285e-04,  8.49277247e-04,  7.05252634e-04,  8.00264825e-04,\n",
       "        8.59973894e-04, -3.30924991e-06, -1.00373269e-04,  1.66579004e-04,\n",
       "        3.27348715e-07,  6.85176856e-05, -8.60093860e-04, -9.59473138e-04,\n",
       "       -2.31467726e-04,  8.92819895e-04, -3.64758744e-04, -6.97819458e-04,\n",
       "        4.87938174e-04,  1.06911662e-04,  1.85101992e-04,  3.65295651e-04,\n",
       "        3.52067233e-04,  5.72612043e-04,  1.23430014e-04,  8.44461902e-05,\n",
       "        9.04525048e-04,  2.78221618e-04, -4.70285653e-04,  6.54218660e-04,\n",
       "        5.21331094e-04,  2.87056697e-04, -3.13783414e-04,  3.33683478e-04,\n",
       "        6.36429759e-04,  7.08103878e-04,  9.41164471e-05, -8.53176811e-04,\n",
       "        2.57761476e-05,  3.70419039e-05,  3.94298084e-04, -9.46896093e-04,\n",
       "        9.70787019e-04, -6.97227719e-04,  5.76143968e-04, -9.42987215e-04,\n",
       "        9.64852807e-04,  7.32482935e-04,  1.26165629e-04, -3.40523722e-04,\n",
       "       -4.50661173e-05,  4.22623161e-05, -6.40920654e-04,  5.74515841e-04,\n",
       "        2.37140179e-04,  3.77793564e-04, -7.25501799e-04,  8.52628960e-04,\n",
       "        5.08253579e-05, -2.03926556e-05, -9.07160749e-04,  4.04875522e-04,\n",
       "        6.76343450e-04,  7.35509151e-04, -6.41752500e-04, -7.85606157e-04,\n",
       "       -5.52371494e-04, -6.02898581e-05, -8.33798142e-04, -8.24011571e-04,\n",
       "       -1.91756961e-04,  1.13928560e-04, -9.50654736e-04, -3.73293413e-04,\n",
       "        6.44779211e-05,  6.80996396e-04,  1.73499109e-04, -6.32383817e-05,\n",
       "       -7.48139631e-04, -6.74209616e-04, -6.94429909e-05,  7.46758247e-04,\n",
       "        5.44286973e-04, -1.48269173e-04,  1.17230891e-04, -9.60577745e-04,\n",
       "       -1.38449672e-04, -4.62622411e-04,  5.80930966e-04, -2.33801358e-04,\n",
       "       -4.76406567e-04, -9.47511406e-04, -1.20031596e-04, -7.19777134e-04,\n",
       "       -1.68521874e-04, -4.06982435e-04, -2.37413638e-04, -3.24833643e-04,\n",
       "       -8.15647363e-04, -1.24841215e-04,  1.69094317e-04, -4.04764403e-04,\n",
       "       -7.64145399e-04, -3.58663558e-04, -9.04713408e-04, -7.58426177e-05,\n",
       "        5.88300463e-04, -2.96134705e-04,  3.16175690e-04,  4.99571790e-04,\n",
       "        8.46842770e-04,  5.62141417e-04,  9.50854563e-04, -9.64668288e-04,\n",
       "       -7.96267530e-04, -6.75815565e-04, -7.46770878e-04, -7.96361943e-04,\n",
       "       -7.78816931e-04, -2.94262660e-04,  1.39616008e-04, -2.87478935e-04,\n",
       "       -8.81625165e-04,  4.98586160e-04,  9.00890809e-05,  4.59040166e-04,\n",
       "        7.19533709e-04,  7.64829398e-04, -8.04648371e-05,  3.65995889e-04,\n",
       "       -5.12357685e-04,  1.91068175e-04,  4.53826913e-04,  9.88666317e-04,\n",
       "       -3.18748964e-04,  2.83933390e-04, -5.73635101e-04, -2.21056704e-04,\n",
       "        8.12509563e-04, -3.90465750e-04, -1.18858101e-04, -9.28497524e-04,\n",
       "       -9.47677589e-04,  8.88276554e-04, -5.70292235e-04,  5.05279051e-04,\n",
       "       -6.96360832e-04, -2.45851290e-04, -8.02293769e-04,  7.50052684e-04,\n",
       "        6.12741453e-04,  5.25846961e-04,  8.37785716e-04, -6.96532734e-05,\n",
       "       -9.31272982e-04,  9.11566487e-04, -4.92853636e-04,  7.84798875e-04,\n",
       "        5.53385995e-04, -1.07907770e-04, -7.66421552e-04, -1.45980361e-04,\n",
       "        6.25353598e-04, -6.96608331e-04,  1.44209625e-04, -7.95185799e-04,\n",
       "        8.72134697e-04, -2.85578979e-04,  9.43730120e-04, -5.70807431e-04,\n",
       "       -9.71772417e-04, -8.62790330e-04, -4.07483574e-04,  4.70959436e-04,\n",
       "       -2.41940015e-05,  9.22351144e-04,  3.10921430e-04,  3.74776602e-04,\n",
       "        2.99634936e-04,  8.14864878e-04, -2.39671470e-04,  7.40733871e-04,\n",
       "       -9.53671464e-04,  2.92108540e-04, -6.81669699e-05,  4.52256209e-05,\n",
       "        6.84300903e-04, -2.84197333e-04, -2.35677959e-04, -1.00476746e-05,\n",
       "       -4.97691617e-05, -3.57496261e-04,  6.24448294e-04, -6.55866868e-04,\n",
       "        7.89199839e-04, -9.34600848e-06,  2.60884059e-04,  3.22314969e-04,\n",
       "       -2.81653411e-05,  1.70630214e-04, -3.14065459e-04,  4.75645531e-04,\n",
       "        2.43010527e-05, -3.28059687e-04, -8.71457567e-04, -9.99808079e-04,\n",
       "        3.12776574e-05, -5.74681035e-04, -1.10965964e-04, -4.20609460e-04,\n",
       "       -8.63882538e-04,  1.06209518e-04,  5.91109041e-04, -2.21096998e-04,\n",
       "       -7.17081770e-04,  3.15343612e-04, -3.84685991e-05, -5.52114274e-04,\n",
       "       -1.10563036e-04, -6.39655555e-05, -3.18309059e-04, -9.95507697e-04,\n",
       "        7.63859251e-04,  3.72600800e-04, -2.52921338e-04,  7.30717438e-04,\n",
       "        4.54590336e-05,  7.17315183e-04, -1.54756301e-04,  7.49366765e-04,\n",
       "       -4.26316274e-06, -6.07736118e-04, -4.71585023e-04,  9.62842489e-04,\n",
       "        5.81061831e-05,  1.02740050e-04,  8.45028611e-04, -6.28840469e-04,\n",
       "       -1.76385875e-04, -8.17892083e-04, -6.67475455e-04, -8.58048676e-04,\n",
       "        3.93060909e-04,  2.73934595e-04,  5.61541296e-04,  2.57175678e-04,\n",
       "        2.11351391e-04,  5.73515426e-04, -2.11640829e-04,  3.17229744e-04,\n",
       "        8.44376103e-04,  3.88071530e-05,  6.29458169e-04, -6.74356939e-04,\n",
       "        6.57582073e-04,  4.68947663e-04,  5.08034718e-04, -9.91878565e-04,\n",
       "       -4.29444299e-05,  3.20611231e-04, -5.82598906e-04, -6.69378729e-04,\n",
       "        6.36390469e-04, -6.82375219e-04, -5.18249988e-04,  8.12183833e-04,\n",
       "       -7.02029676e-04,  8.54537473e-04,  6.54621108e-05,  4.40570584e-04,\n",
       "       -3.01244028e-04, -5.42773458e-04, -8.94753437e-04, -6.12473523e-05,\n",
       "       -5.10223850e-04, -3.07603594e-04,  8.11145292e-04, -7.64791039e-04,\n",
       "       -6.30928029e-04, -5.26367920e-04, -6.60374179e-04, -8.84062261e-04,\n",
       "       -1.11004112e-04,  9.44597705e-04,  8.03653733e-04, -5.27409778e-04,\n",
       "       -8.13750725e-04, -2.25739481e-04, -9.26678185e-04, -5.06773940e-04,\n",
       "       -5.94780664e-04,  3.02512170e-04, -7.56904366e-04,  1.25058417e-04,\n",
       "        2.28690144e-04,  5.31331520e-04, -2.02039722e-04, -9.77166230e-04,\n",
       "        5.22166723e-04, -5.90649375e-04,  4.88575432e-04,  1.97475427e-04,\n",
       "        8.81741988e-04,  1.53133631e-04, -1.82746415e-04,  6.48876885e-04,\n",
       "       -7.06992170e-04, -8.38906271e-04,  3.78916971e-04, -2.57695210e-04,\n",
       "       -4.18384065e-04, -1.92487962e-04, -9.87509266e-04,  2.60536672e-05,\n",
       "       -1.05665444e-04, -2.97141785e-04,  2.50064360e-04,  4.69339371e-04,\n",
       "        6.34260650e-04, -7.91374710e-04, -4.98899433e-04, -8.78746971e-04,\n",
       "       -8.94903671e-04, -3.73006100e-04, -1.27370600e-04, -8.21263297e-04,\n",
       "       -5.37631975e-04, -2.15177541e-04,  6.34268741e-04,  1.56860828e-04,\n",
       "        8.31468846e-04, -8.31620942e-04, -4.57587477e-04, -8.04083320e-05,\n",
       "        8.80017760e-04,  1.10635039e-04,  1.53997666e-04,  1.29078384e-04,\n",
       "        2.92262092e-04, -9.39594756e-04,  3.25440167e-04,  5.46468480e-04,\n",
       "        5.28632663e-04,  4.43988800e-04, -8.08636891e-04, -4.05977713e-04,\n",
       "        8.34891107e-04, -5.73091493e-05, -9.43677907e-04,  4.78363741e-04,\n",
       "       -6.04513858e-04,  6.68149209e-04,  5.37377840e-04, -5.04567404e-04,\n",
       "        2.56942760e-04,  5.41664136e-04, -3.58530524e-04, -1.51603454e-04,\n",
       "        9.16957157e-04,  9.06320813e-04, -9.39296500e-04,  7.56730791e-04,\n",
       "        9.88804852e-04, -2.84017093e-04,  2.45934498e-04, -2.80335196e-04,\n",
       "        8.64544418e-04, -2.83284189e-05,  5.63630834e-04,  9.21289437e-04,\n",
       "        4.11024579e-04, -7.12039007e-04, -1.92583087e-04,  9.78024036e-05,\n",
       "        2.03407530e-04,  2.95421371e-04,  9.44935775e-04,  4.40109958e-04,\n",
       "        9.91389970e-04, -8.65770329e-04, -5.75441576e-04,  1.98630572e-04,\n",
       "        3.65617278e-04, -9.91179913e-05, -6.91164983e-04, -3.21166270e-04,\n",
       "       -8.52757192e-04,  9.41071252e-04,  3.72443435e-04, -7.87941914e-04,\n",
       "        3.18696751e-04,  4.17383446e-04, -5.63898589e-04, -5.91279240e-04,\n",
       "        1.03836537e-04,  8.96204496e-04, -9.64628241e-04,  6.28948214e-07,\n",
       "       -6.86494575e-04, -9.32250041e-05,  3.04100045e-04, -5.02996671e-04,\n",
       "       -2.77600513e-04,  6.75587653e-05, -6.36222132e-04,  7.28657702e-04,\n",
       "        4.37842129e-04, -8.55853548e-04, -2.14897154e-04,  3.16452992e-04,\n",
       "       -8.32759368e-04, -7.06891296e-04, -8.45374132e-04, -5.49859309e-04,\n",
       "        8.85609654e-04,  7.07704807e-04,  2.88571347e-04, -8.55457096e-04,\n",
       "        5.74323174e-04,  4.63341712e-04,  1.18975640e-05, -8.84293811e-04,\n",
       "       -1.88373087e-04,  1.90863611e-05, -7.75794266e-04,  2.47015967e-04,\n",
       "        4.83765616e-05, -7.06002931e-04, -8.26940988e-04,  6.04218978e-04,\n",
       "       -8.35049141e-04, -5.57978638e-04,  5.58012514e-04, -4.86352437e-05,\n",
       "       -3.05436610e-04, -5.19437774e-04, -1.19794844e-04,  5.27171593e-04,\n",
       "       -5.94644051e-04, -4.97717352e-04, -4.94862325e-04, -4.75634821e-04,\n",
       "       -7.98009394e-04, -9.75646486e-04,  7.58216600e-04,  7.99675006e-04,\n",
       "       -4.28431755e-04, -9.32806230e-04, -1.87251571e-04, -3.70827212e-04,\n",
       "        9.09860828e-04,  2.94014229e-04, -5.97814564e-04, -3.35828547e-04,\n",
       "       -9.90248402e-04,  1.94411987e-04, -3.98836855e-04, -2.70870456e-04,\n",
       "        5.17648936e-04,  7.59902236e-04,  4.38382616e-04, -6.82041631e-04,\n",
       "        6.69864181e-04, -9.63179336e-04, -6.98728778e-04, -8.00600043e-04,\n",
       "       -2.26293094e-04,  4.79838855e-05, -3.77228251e-04,  1.84537173e-04,\n",
       "        9.20718419e-04,  6.67805434e-04, -1.05482577e-04,  9.09295806e-04,\n",
       "        1.55689471e-04, -1.97391273e-04, -6.59495126e-04,  6.47390145e-04,\n",
       "       -9.06960224e-04, -1.89660554e-04,  7.69239676e-04, -2.58686079e-04,\n",
       "        1.60619253e-04, -7.34611531e-04,  4.97807981e-04,  7.37306604e-04,\n",
       "       -9.30854061e-04, -3.27785499e-04,  7.89273763e-04,  2.93382182e-04,\n",
       "        1.45411491e-06,  3.43308457e-05, -9.86542902e-04,  9.93674970e-04,\n",
       "       -2.00134033e-04, -4.88732127e-04,  2.74924038e-04,  1.02997066e-04,\n",
       "       -5.93158940e-04,  5.79264422e-04, -2.50346668e-04, -6.17838115e-04,\n",
       "        7.23570818e-04,  6.46347529e-04,  8.82028078e-04,  1.16339448e-04,\n",
       "        5.10001191e-05, -7.92962092e-04,  4.64888348e-04,  9.36113356e-04,\n",
       "       -6.79640798e-05, -1.76296948e-04, -3.81316902e-04, -4.91876599e-05,\n",
       "       -7.61743519e-04,  5.68924414e-04,  1.49088621e-04,  9.29274538e-04,\n",
       "       -6.42440573e-04, -5.08923025e-04, -6.23465050e-04, -7.27669219e-04,\n",
       "        2.75656697e-04,  4.89461643e-04,  1.34196991e-04,  3.54074960e-04,\n",
       "       -9.38827521e-04, -1.06959102e-04, -7.74288666e-04,  2.95213686e-04,\n",
       "       -2.68613570e-04,  8.88299954e-04, -3.43434105e-04,  6.83821912e-04,\n",
       "        4.11486864e-04,  1.36439325e-04, -4.04620187e-06,  8.17253371e-04,\n",
       "        2.36173626e-04,  8.25822819e-04,  3.33538541e-04,  5.42311172e-04,\n",
       "        5.10191196e-04, -7.62878160e-04, -5.78860054e-04,  1.23417616e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.get_vector('ferrei!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oi', 1.0000001192092896),\n",
       " ('me', 0.026572521775960922),\n",
       " ('ferrei!', -0.022045189514756203)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similar_by_vector(model_w2v.wv.get_vector('oi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = KeyedVectors.load_word2vec_format('D:/txt/cbow_s1000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v.add_vector(\"ferrei!\", model_w2v.wv.get_vector('ferrei!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ [w2v.get_vector(w) for w in sentence.split()] for sentence in [\"hoje  um bom dia\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_w2v.update({'ferrei!': model_w2v.wv.get_vector('ferrei!')})\n",
    "# result = get_w2v(\"eu me ferrei!\", dict_w2v)\n",
    "# result.shape, result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_to_binary('D:/txt/cbow_s1000.txt', 'D:/txt/cbow_1000.vocab', 'D:/txt/cbow_1000.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
