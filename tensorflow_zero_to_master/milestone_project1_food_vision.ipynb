{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 1 - Food Vision Big\n",
    "\n",
    "## What we're going to cover?\n",
    "\n",
    "* Using tensorflow dataset to download and explore all of food 101\n",
    "* Create a preprocessing function for our data\n",
    "* Batching and prepare datasets for modeling (making them run fast)\n",
    "* Setting up mixed precision training (faster model training)\n",
    "* Building and training a feature extraction model\n",
    "* Fine-tuning your feature extraction model to the beat the DeepFood paper\n",
    "* Evaluating your model results on Tensorboard\n",
    "* Evaluating your model results by making and plotting predictions\n",
    "\n",
    "\n",
    "see: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU\n",
    "\n",
    "Google Colab offers free GPUs (thank you Google), however, not all of them are compatible with mixed precision training.\n",
    "\n",
    "Google Colab offers:\n",
    "* k80 (not compatible)\n",
    "* p100 (not compatible)\n",
    "* tesla T4 (compatible)\n",
    "\n",
    "Knowing this, in order to use mixed precision training we need access to a Tesla T4 (from within Google Colab) or if we're using own hardware, our GPU need scores of 7.0+ (see here: https://developer.nvidida.com/cuda-gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "\n",
    "In past modules, we've created a brunch of helper functions to do small task required for our notebooks. Rather than rewrite all these, we can import a script and load them in from threre. The script we've got available can be found on github: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request as ur\n",
    "# uncomment this line below and run it to download helper_functions file\n",
    "# ur.urlretrieve('https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py', filename='helper_functions.py')\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, walk_through_dir, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow dataset \n",
    "\n",
    "\n",
    "- see: https://www.tensorflow.org/datasets?hl=pt-br\n",
    "- see: https://www.tensorflow.org/datasets/catalog/overview?hl=pt-br\n",
    "- see: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\tensorflow_certificate\\.tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all dataset available in TFDS\n",
    "# dataset_list = tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is our target dataset food101 in the list of TFDS?\n",
    "# print(f\"food101\" in dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data (takes 5-6 minutes in Google Colab)\n",
    "# (train_data, test_data), ds_info = tfds.load(name='food101', \n",
    "#                                              split=['train', 'validation'],\n",
    "#                                              shuffle_files=True,\n",
    "#                                              as_supervised=True, # data gets retuned in tuple format (data, label)\n",
    "#                                              with_info=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we know about our data:\n",
    "* In `unit8` datatype\n",
    "* Comprised of all different size tensors (different size images)\n",
    "* Not scaled (pixel values are between 0 & 255)\n",
    "\n",
    "we know models like:\n",
    "\n",
    "* data in `float32` dtype (or for mixed precision `float16` and  `float32`)\n",
    "* for batches, Tensorflow likes all of the tensors within a batch to be of the same size\n",
    "* scaled (values between 0 & 1) also called normalized tensor generally perform better\n",
    "\n",
    "with these point in mind, we got a few things we can tackle with a preprocessing function. Since we're going to be using an EfficientNet petrained model from `tf.keras.application` we don't need to rescale our data (these architetures have rescaling built-in).\n",
    "\n",
    "these main our functions need to:\n",
    "1. reshape our images to all the same size.\n",
    "2. convert the dtype of our model image tensor from `unit8` to `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function to preprocessing images\n",
    "def preprocessing_img(image, label, img_shape=224):\n",
    "    \"\"\"\n",
    "    Converts image datatype from 'unit8' to 'float32' and reshape image to [img_shape, img_shape, color_channels]\n",
    "    Args:\n",
    "        image (unit8) required\n",
    "        label (int) required\n",
    "        img_shape (int) optional\n",
    "    Returns:\n",
    "        (float32_image, label)\n",
    "    \"\"\"\n",
    "\n",
    "    image = tf.image.resize(image, [img_shape, img_shape]) # reshape target image\n",
    "    return tf.cast(image, tf.float32), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch and Prepare Datasets\n",
    "\n",
    "We're now going to make our data input pipeline run really fast. For more resources follow guide: https://www.tensorflow.org/guide/data_performance?hl=pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preprocessing function to training and parallelize\n",
    "# train_data = train_data.map(map_func=preprocessing_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
    "# traind_data = traind_data.shuffle(buffer_size=len(train_data)).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# map preprocessing function to test data\n",
    "# test_data = test_data.map(map_func=preprocessing_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Hey tensorflow, map this preprocessing function (`preprocessing_img`) across our training dataset, then shuffle a number of elments and then batch them finally make sure you prepare new batches (prefetch) whilist the model is looking through finding patterns the current batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE = os.path.join('..', 'storage')\n",
    "ZIP_PATH = f'{STORAGE}/zip'\n",
    "TRANSFER_LEARNING_PATH = f'{STORAGE}/transfer_learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_food_classes_10_percent.zip'\n",
    "folder = filename.split('.')[0]\n",
    "url = f'https://storage.googleapis.com/ztm_tf_course/food_vision/{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f'{TRANSFER_LEARNING_PATH}/{folder}/train'\n",
    "test_dir = f'{TRANSFER_LEARNING_PATH}/{folder}/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7575 files belonging to 101 classes.\n",
      "Found 25250 files belonging to 101 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 101), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup data inputs\n",
    "IMG_SIZE = (224, 224)\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                                label_mode='categorical', # 101 classes\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                label_mode='categorical',\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                shuffle=False) # don't shuffle test data for prediction analysis\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a modelling callbacks\n",
    "\n",
    "What are callbacks?\n",
    "\n",
    "* Callbacks are tools which can `add help funcionality` to your model during training evaluation or inference.\n",
    "* Some popular callbacks include:\n",
    "    * Tensorboard (`tf.keras.callbacks.Tensorboard()`) - Log the performace of multiple models and then view and compare these models in a visual way. helpful to compare results\n",
    "    * ModelCheckpoint (`tf.keras.callbacks.ModelCheckpoint()`) - save your model as it trains so you can stop training if need and come back to continue off where you left.\n",
    "    * Early Stopping (`tf.keras.callbacks.EarlyStopping()`) - leave your model training for an arbitrary amount of time and have it stop training automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model check point path\n",
    "checkpoint_dir = f'{TRANSFER_LEARNING_PATH}/tensorflow_hub/milestone1_model_checkpoint_weight'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = f'{checkpoint_dir}/checkpoint.ckpt'\n",
    "\n",
    "# create a model checkpoint callback that saves the model's weights only\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                               save_weights_only=True,\n",
    "                                                               save_best_only=True,\n",
    "                                                               save_freq='epoch', # save every epoch\n",
    "                                                               monitor='val_accuracy', \n",
    "                                                               verbose=0) # don't print anything whether or not model is being saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup mixed precision training\n",
    "\n",
    "First and foremost, for a deep understanding of mixed precision training, check out tensorflow guide: https://www.tensorflow.org/guide/mixed_precision\n",
    "\n",
    "Mixed precision utilizes a combination of float32 and float16 data types to speed up model performance\n",
    "\n",
    "see: https://www.cherryservers.com/blog/introduction-to-gpu-programming-with-cuda-and-python  \n",
    "see: https://en.wikipedia.org/wiki/Half-precision_floating-point_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1650 Ti, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "# turn on mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\") # set global data policy to mixed precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build feature extraction model\n",
    "\n",
    "see: https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy  \n",
    "see: https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24274472/24274472 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# create a base model\n",
    "input_shape=(224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetV2B0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# create function model\n",
    "inputs = tf.keras.layers.Input(shape=input_shape, name='input_shape')\n",
    "# Note: EfficienteBX models have rescaling built-in but if your model doesn't you can have a layer\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x)\n",
    "x = base_model(inputs, training=False) # make sure layers which should be in inference model only \n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_2D')(x)\n",
    "x = tf.keras.layers.Dense(len(test_data.class_names), name='dense_layer')(x)\n",
    "outputs = tf.keras.layers.Activation('softmax', dtype=tf.float32, name='softmax_float32')(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_shape (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, None, None, 1280)  5919312  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling_2D (  (None, 1280)             0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_layer (Dense)         (None, 101)               129381    \n",
      "                                                                 \n",
      " softmax_float32 (Activation  (None, 101)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,048,693\n",
      "Trainable params: 129,381\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking layer dtype policies (are we using mixed precision?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: input_shape,\n",
      "trainable: True,\n",
      "policy: <Policy \"float32\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: efficientnetv2-b0,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: global_average_pooling_2D,\n",
      "trainable: True,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: dense_layer,\n",
      "trainable: True,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: softmax_float32,\n",
      "trainable: True,\n",
      "policy: <Policy \"float32\">,\n",
      "dtype: float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the dtype_policies attributes of layers in the model\n",
    "for layer in model.layers:\n",
    "    print(f'layer: {layer.name},\\ntrainable: {layer.trainable},\\npolicy: {layer.dtype_policy},\\ndtype: {layer.dtype}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the above we see:\n",
    "* `layer.name`: the human readable name of a particular layer\n",
    "* `layer.trainable`: is the layer trainable or not? (if `False`, the weights are frozen)\n",
    "* `layer.dtype`: the datatype a layer stores its variables in\n",
    "* `layer.dtype_policy`: the data type policy a layer computes on its variables with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: input_4,\n",
      "trainable: False,\n",
      "policy: <Policy \"float32\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: rescaling_3,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: normalization_3,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: stem_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: stem_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: stem_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block1a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block1a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block1a_project_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2a_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2a_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2a_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block2b_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3a_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3a_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3a_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block3b_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4b_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block4c_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5b_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5c_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5d_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block5e_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6a_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6b_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6c_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6d_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6e_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6f_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6g_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_expand_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_expand_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_expand_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_dwconv2,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_se_squeeze,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_se_reshape,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_se_reduce,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_se_expand,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_se_excite,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_project_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_project_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_drop,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: block6h_add,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: top_conv,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: top_bn,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n",
      "layer: top_activation,\n",
      "trainable: False,\n",
      "policy: <Policy \"mixed_float16\">,\n",
      "dtype: float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the dtype_policies attributes of layers in the model in the base_model\n",
    "for layer in model.layers[1].layers:\n",
    "    print(f'layer: {layer.name},\\ntrainable: {layer.trainable},\\npolicy: {layer.dtype_policy},\\ndtype: {layer.dtype}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the feature extraction model\n",
    "\n",
    "if our goal is to fine-tuning a pretrained model, the general order doing thing is:\n",
    "1. Build a feature extraction model (train a couple out layer with base model layer frozen)\n",
    "2. Fine-tune some of the fronze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#               optimizer=tf.keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: ..\\storage/transfer_learning/tensorflow_hub/milestone1_feature_extraction/20240406-112028\n",
      "Epoch 1/3\n",
      "237/237 [==============================] - 156s 579ms/step - loss: 3.1096 - accuracy: 0.3387 - val_loss: 2.4546 - val_accuracy: 0.4537\n",
      "Epoch 2/3\n",
      "237/237 [==============================] - 119s 489ms/step - loss: 1.8239 - accuracy: 0.5999 - val_loss: 2.0377 - val_accuracy: 0.5143\n",
      "Epoch 3/3\n",
      "237/237 [==============================] - 111s 456ms/step - loss: 1.4193 - accuracy: 0.6774 - val_loss: 1.8869 - val_accuracy: 0.5350\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_101_food_classes_feature_extraction = model.fit(train_data, # directory of all images after have been passed of batches\n",
    "                                                        epochs=3, # size of epoch of training\n",
    "                                                        steps_per_epoch=len(train_data), # steps of training size equal to train data\n",
    "                                                        validation_data=test_data, # step validation data include test_data\n",
    "                                                        validation_steps=int(0.15 * len(test_data)), # which size the step will be 15% of all test data\n",
    "                                                        callbacks=[model_checkpoint_callback, \n",
    "                                                                   create_tensorboard_callback(\n",
    "                                                                       dir_name=f'{TRANSFER_LEARNING_PATH}/tensorflow_hub',\n",
    "                                                                       experiment_name='milestone1_feature_extraction')]) # callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 243s 307ms/step - loss: 1.5793 - accuracy: 0.6042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.579253911972046, 0.6041584014892578]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on whole test data\n",
    "feature_extraction_result = model.evaluate(test_data)\n",
    "feature_extraction_result\n",
    "\n",
    "# underfitting - when value of loss is greater than accuracy\n",
    "# overfitting - when value of loss is less than accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
